{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"03_Pytorch_EmbeddingsTraining_LM.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOZyGhYUhHtL",
        "colab_type": "text"
      },
      "source": [
        "# Семинар 3: Представления слов: продолжение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fID9IxEs4khf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBl0RozNEUcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d06d7e19-77a8-4a80-b4bc-0dac8fc87e8a"
      },
      "source": [
        "%%writefile requirements.txt\n",
        "gensim\n",
        "pandas\n",
        "razdel\n",
        "sklearn\n",
        "allennlp\n",
        "torch==1.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U333X2sEruh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b96516f7-3042-40f4-b4a3-ed5bcd2910f6"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.0.5)\n",
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.0)\n",
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/49/bf0ec241496a82c9dd2f0b6ff6f8156b6b2b72b849df8c00a4f2bcf61485/allennlp-1.0.0-py3-none-any.whl (473kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 11.1MB/s \n",
            "\u001b[?25hCollecting torch==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 20kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 4)) (0.22.2.post1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (1.14.37)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (4.41.1)\n",
            "Collecting transformers<2.12,>=2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 52.5MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (0.7)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (3.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (3.0.12)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (2.2.4)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (2.23.0)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 5)) (3.6.4)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->-r requirements.txt (line 1)) (2.49.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp->-r requirements.txt (line 5)) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp->-r requirements.txt (line 5)) (1.17.37)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 59.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp->-r requirements.txt (line 5)) (20.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp->-r requirements.txt (line 5)) (2019.12.20)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r requirements.txt (line 5)) (49.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp->-r requirements.txt (line 5)) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 5)) (2020.6.20)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp->-r requirements.txt (line 5)) (3.12.4)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 5)) (8.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 5)) (1.9.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 5)) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->allennlp->-r requirements.txt (line 5)) (0.15.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp->-r requirements.txt (line 5)) (3.1.0)\n",
            "Building wheels for collected packages: jsonnet, overrides, sacremoses\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321651 sha256=7e356372089ce82bef6a88c0ade1f0956545f68e2bb7ccf496c880c7d4ab6c50\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=65521e107b23f161b1b077840a6c6157524eec68c30e508b3eca40a87dff0799\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=8880b4f77a2bc316f1d009c7af8f4656aa1ddfcbe8085a1eb1f5da2add0d18ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built jsonnet overrides sacremoses\n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: allennlp 1.0.0 has requirement torch<1.6.0,>=1.5.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: razdel, sentencepiece, sacremoses, tokenizers, transformers, jsonnet, torch, overrides, jsonpickle, tensorboardX, allennlp\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed allennlp-1.0.0 jsonnet-0.16.0 jsonpickle-1.4.1 overrides-3.0.0 razdel-0.5.0 sacremoses-0.0.43 sentencepiece-0.1.91 tensorboardX-2.1 tokenizers-0.7.0 torch-1.4.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWuio1OBEuef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "c3f0fc72-079a-4ae1-c78d-e8c216347294"
      },
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
        "!gzip -d lenta-ru-news.csv.gz\n",
        "!head -n 2 lenta-ru-news.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-12 14:24:11--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 52.74.223.119\n",
            "Connecting to github.com (github.com)|52.74.223.119|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200812%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200812T142411Z&X-Amz-Expires=300&X-Amz-Signature=dc3fe392879bcbd391e3b6dcdeec6bd1ca62b55b2fe739cf18b40e770c626578&X-Amz-SignedHeaders=host&actor_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-08-12 14:24:12--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200812%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200812T142411Z&X-Amz-Expires=300&X-Amz-Signature=dc3fe392879bcbd391e3b6dcdeec6bd1ca62b55b2fe739cf18b40e770c626578&X-Amz-SignedHeaders=host&actor_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 54.231.33.139\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|54.231.33.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  14.1MB/s    in 38s     \n",
            "\n",
            "2020-08-12 14:24:50 (13.3 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
            "\n",
            "url,title,text,topic,tags\n",
            "https://lenta.ru/news/2018/12/14/cancer/,Названы регионы России с самой высокой смертностью от рака,\"Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.\",Россия,Общество\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLuLCuuNExQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fd0fed3b-adbd-4d9f-f616-71b701bb40e0"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import datetime as dt\n",
        "from razdel import tokenize, sentenize\n",
        "from string import punctuation\n",
        "\n",
        "def get_date(url):\n",
        "    dates = re.findall(r\"\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d\", url)\n",
        "    return next(iter(dates), None)\n",
        "\n",
        "dataset = pd.read_csv(\"lenta-ru-news.csv\", sep=',', quotechar='\\\"', escapechar='\\\\', encoding='utf-8', header=0)\n",
        "dataset[\"date\"] = dataset[\"url\"].apply(lambda x: dt.datetime.strptime(get_date(x), \"%Y/%m/%d\"))\n",
        "dataset = dataset[dataset[\"date\"] > \"2017-01-01\"]\n",
        "dataset[\"text\"] = dataset[\"text\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
        "dataset[\"title\"] = dataset[\"title\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
        "train_dataset = dataset[dataset[\"date\"] < \"2018-04-01\"]\n",
        "test_dataset = dataset[dataset[\"date\"] > \"2018-04-01\"]\n",
        "\n",
        "texts = []\n",
        "for text in train_dataset[\"text\"]:\n",
        "    for sentence in sentenize(text):\n",
        "        texts.append([token.text.lower() for token in tokenize(sentence.text) if token.text not in punctuation])\n",
        "    \n",
        "for title in train_dataset[\"title\"]:\n",
        "    texts.append([token.text.lower() for token in tokenize(title) if token.text not in punctuation])\n",
        "\n",
        "assert len(texts) == 827217\n",
        "assert len(texts[0]) > 0\n",
        "assert texts[0][0].islower()\n",
        "print(texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['возобновление', 'нормального', 'сотрудничества', 'между', 'россией', 'и', 'нато', 'невозможно', 'пока', 'москва', 'не', 'будет', 'соблюдать', 'нормы', 'международного', 'права']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6CwYN9iNxf",
        "colab_type": "text"
      },
      "source": [
        "## Предобработка и батчинг"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXw1zgBnFzux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "89505b48-8e3b-4c03-e04b-0a2faa8ffcef"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2index = {\n",
        "            \"<unk>\": 0\n",
        "        }\n",
        "        self.index2word = [\"<unk>\"]\n",
        "\n",
        "    def build(self, texts, min_count=5):\n",
        "        words_counter = Counter(token for tokens in texts for token in tokens)\n",
        "        #self.vocab = self.word2index.items()\n",
        "        for word, count in words_counter.most_common():\n",
        "            if count >= min_count:\n",
        "                self.word2index[word] = len(self.word2index)\n",
        "        self.index2word = [word for word, _ in sorted(self.word2index.items(), key=lambda x: x[1])]\n",
        "        self.vocab = self.word2index.keys()\n",
        "    \n",
        "    @property\n",
        "    def size(self):\n",
        "        return len(self.index2word)\n",
        "    \n",
        "    def top(self, n=100):\n",
        "        return self.index2word[1:n+1]\n",
        "    \n",
        "    def get_index(self, word):\n",
        "        return self.word2index.get(word, 0)\n",
        "    \n",
        "    def get_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def vocab(self):\n",
        "        return self.vocab\n",
        "\n",
        "vocabulary = Vocabulary()\n",
        "vocabulary.build(texts)\n",
        "assert vocabulary.word2index[vocabulary.index2word[10]] == 10\n",
        "print(vocabulary.size)\n",
        "print(vocabulary.top(100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112084\n",
            "['в', 'и', 'на', '«', '»', 'что', 'с', 'по', '—', 'не', 'из', 'этом', 'об', 'о', 'он', 'за', 'года', 'россии', 'к', 'его', 'для', 'как', 'также', 'от', 'а', 'это', 'сообщает', 'до', 'году', 'после', 'сша', 'у', 'во', 'время', 'был', 'при', 'заявил', 'со', 'словам', 'рублей', 'будет', 'ее', 'она', 'но', 'ранее', 'их', 'они', 'было', 'тысяч', 'более', 'того', 'том', 'мы', 'были', 'я', 'которые', 'все', 'который', 'человек', 'под', '2016', 'из-за', 'лет', '2017', 'украины', 'марта', 'процентов', 'чтобы', 'долларов', 'глава', 'президент', 'этого', 'отметил', 'же', 'сказал', 'так', 'января', 'или', 'страны', 'ру', 'то', 'еще', 'области', 'данным', 'была', 'президента', 'около', 'сообщил', 'февраля', 'однако', 'компании', 'может', 'уже', 'один', 'рассказал', 'только', 'процента', '1', '10', 'июня']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIZSh1dGD4E2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f901352c-a4ec-4e34-a44d-d8fe0f56148e"
      },
      "source": [
        "def build_contexts(tokenized_texts, vocabulary, window_size):\n",
        "    contexts = []\n",
        "    for tokens in tokenized_texts:\n",
        "        for i in range(len(tokens)):\n",
        "            central_word = vocabulary.get_index(tokens[i])\n",
        "            context = [vocabulary.get_index(tokens[i + delta]) for delta in range(-window_size, window_size + 1) \n",
        "                       if delta != 0 and i + delta >= 0 and i + delta < len(tokens)]\n",
        "            if len(context) != 2 * window_size:\n",
        "                continue\n",
        "\n",
        "            contexts.append((central_word, context))\n",
        "            \n",
        "    return contexts\n",
        "\n",
        "contexts = build_contexts(texts, vocabulary, window_size=2)\n",
        "print(contexts[:5])\n",
        "print(vocabulary.get_word(contexts[0][0]), [vocabulary.get_word(index) for index in contexts[0][1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1568, [17232, 26343, 135, 371]), (135, [26343, 1568, 371, 2]), (371, [1568, 135, 2, 695]), (2, [135, 371, 695, 2140]), (695, [371, 2, 2140, 216])]\n",
            "сотрудничества ['возобновление', 'нормального', 'между', 'россией']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBMYeN88Irey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def get_next_batch(contexts, window_size, batch_size, epochs_count):\n",
        "    assert batch_size % (window_size * 2) == 0\n",
        "    central_words, contexts = zip(*contexts)\n",
        "    batch_size //= (window_size * 2)\n",
        "    \n",
        "    for epoch in range(epochs_count):\n",
        "        indices = np.arange(len(contexts))\n",
        "        np.random.shuffle(indices)\n",
        "        batch_begin = 0\n",
        "        while batch_begin < len(contexts):\n",
        "            batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
        "            batch_contexts, batch_centrals = [], []\n",
        "            for data_ind in batch_indices:\n",
        "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
        "                batch_contexts.extend(context)\n",
        "                batch_centrals.extend([central_word] * len(context))\n",
        "                \n",
        "            batch_begin += batch_size\n",
        "            # torch? что за torch?\n",
        "            yield torch.cuda.LongTensor(batch_contexts), torch.cuda.LongTensor(batch_centrals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L2oOckSnoC-",
        "colab_type": "text"
      },
      "source": [
        "## Модель и обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwPJsMaKO7O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "import time\n",
        "\n",
        "class SkipGramModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        projections = self.embeddings.forward(inputs)\n",
        "        output = self.out_layer.forward(projections)\n",
        "        return output\n",
        "      \n",
        "\n",
        "model = SkipGramModel(vocabulary.size, 32)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = model.to(device)\n",
        "\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_function = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "for step, (batch_contexts, batch_centrals) in enumerate(get_next_batch(contexts, window_size=2, batch_size=512, epochs_count=5)):\n",
        "    logits = model(batch_centrals) # Прямой проход\n",
        "    loss = loss_function(logits, batch_contexts) # Подсчёт ошибки\n",
        "    loss.backward() # Подсчёт градиентов dL/dw\n",
        "    optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
        "    optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "\n",
        "embeddings = model.embeddings.weight.cpu().data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BAOODW21-uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('embs1.npy', 'ab') as f:\n",
        "  np.save(f, embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPJxZwYgo2JH",
        "colab_type": "text"
      },
      "source": [
        "## Базовые проверки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh2McM2dTkVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3601e916-a2b7-4ada-e66c-f8782544788f"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def most_similar(embeddings, vocabulary, word):\n",
        "    word_emb = embeddings[vocabulary.get_index(word)]\n",
        "    \n",
        "    similarities = cosine_similarity([word_emb], embeddings)[0]\n",
        "    top10 = np.argsort(similarities)[-10:]\n",
        "    \n",
        "    return [vocabulary.get_word(index) for index in reversed(top10)]\n",
        "\n",
        "most_similar(embeddings, vocabulary, 'путин')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['путин',\n",
              " 'мединский',\n",
              " 'сафронов',\n",
              " 'аристархов',\n",
              " 'колокольцев',\n",
              " 'семашко',\n",
              " 'колычев',\n",
              " 'гройсман',\n",
              " 'президент',\n",
              " 'брынзак']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAWj2Sf-Tmvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "7fad83af-3a44-4dea-916d-5adb230b77c2"
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig\n",
        "\n",
        "\n",
        "def get_tsne_projection(word_vectors):\n",
        "    tsne = TSNE(n_components=2, verbose=100, n_iter=500)\n",
        "    return scale(tsne.fit_transform(word_vectors))\n",
        "\n",
        "def get_pca_projection(word_vectors):\n",
        "    pca = PCA(n_components=2)\n",
        "    return scale(pca.fit_transform(word_vectors))\n",
        "    \n",
        "    \n",
        "def visualize_embeddings(embeddings, vocabulary, word_count, method=\"pca\"):\n",
        "    word_vectors = embeddings[1: word_count + 1]\n",
        "    words = vocabulary.index2word[1: word_count + 1]\n",
        "    get_projections = get_pca_projection if method == \"pca\" else get_tsne_projection\n",
        "    projections = get_projections(word_vectors)\n",
        "    draw_vectors(projections[:, 0], projections[:, 1], color='green', token=words)\n",
        "    \n",
        "    \n",
        "visualize_embeddings(embeddings, vocabulary, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      if (url in hashes) {\n",
              "        element.crossOrigin = \"anonymous\";\n",
              "        element.integrity = \"sha384-\" + hashes[url];\n",
              "      }\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"ed149242-ee80-4db0-b370-6046bf61aed8\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"690dfd8c-9797-4160-9739-5794400bc121\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\"}],\"center\":[{\"id\":\"1014\"},{\"id\":\"1018\"}],\"left\":[{\"id\":\"1015\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1036\"}],\"title\":{\"id\":\"1041\"},\"toolbar\":{\"id\":\"1026\"},\"x_range\":{\"id\":\"1003\"},\"x_scale\":{\"id\":\"1007\"},\"y_range\":{\"id\":\"1005\"},\"y_scale\":{\"id\":\"1009\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{\"overlay\":{\"id\":\"1025\"}},\"id\":\"1021\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1045\"},\"ticker\":{\"id\":\"1012\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"ResetTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1001\"},\"glyph\":{\"id\":\"1034\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1035\"},\"selection_glyph\":null,\"view\":{\"id\":\"1037\"}},\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1020\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1019\"},{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1038\"}]},\"id\":\"1026\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"token\":[\"\\u0432\",\"\\u0438\",\"\\u043d\\u0430\",\"\\u00ab\",\"\\u00bb\",\"\\u0447\\u0442\\u043e\",\"\\u0441\",\"\\u043f\\u043e\",\"\\u2014\",\"\\u043d\\u0435\",\"\\u0438\\u0437\",\"\\u044d\\u0442\\u043e\\u043c\",\"\\u043e\\u0431\",\"\\u043e\",\"\\u043e\\u043d\",\"\\u0437\\u0430\",\"\\u0433\\u043e\\u0434\\u0430\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0438\",\"\\u043a\",\"\\u0435\\u0433\\u043e\",\"\\u0434\\u043b\\u044f\",\"\\u043a\\u0430\\u043a\",\"\\u0442\\u0430\\u043a\\u0436\\u0435\",\"\\u043e\\u0442\",\"\\u0430\",\"\\u044d\\u0442\\u043e\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0430\\u0435\\u0442\",\"\\u0434\\u043e\",\"\\u0433\\u043e\\u0434\\u0443\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\",\"\\u0441\\u0448\\u0430\",\"\\u0443\",\"\\u0432\\u043e\",\"\\u0432\\u0440\\u0435\\u043c\\u044f\",\"\\u0431\\u044b\\u043b\",\"\\u043f\\u0440\\u0438\",\"\\u0437\\u0430\\u044f\\u0432\\u0438\\u043b\",\"\\u0441\\u043e\",\"\\u0441\\u043b\\u043e\\u0432\\u0430\\u043c\",\"\\u0440\\u0443\\u0431\\u043b\\u0435\\u0439\",\"\\u0431\\u0443\\u0434\\u0435\\u0442\",\"\\u0435\\u0435\",\"\\u043e\\u043d\\u0430\",\"\\u043d\\u043e\",\"\\u0440\\u0430\\u043d\\u0435\\u0435\",\"\\u0438\\u0445\",\"\\u043e\\u043d\\u0438\",\"\\u0431\\u044b\\u043b\\u043e\",\"\\u0442\\u044b\\u0441\\u044f\\u0447\",\"\\u0431\\u043e\\u043b\\u0435\\u0435\",\"\\u0442\\u043e\\u0433\\u043e\",\"\\u0442\\u043e\\u043c\",\"\\u043c\\u044b\",\"\\u0431\\u044b\\u043b\\u0438\",\"\\u044f\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435\",\"\\u0432\\u0441\\u0435\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0439\",\"\\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\",\"\\u043f\\u043e\\u0434\",\"2016\",\"\\u0438\\u0437-\\u0437\\u0430\",\"\\u043b\\u0435\\u0442\",\"2017\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u044b\",\"\\u043c\\u0430\\u0440\\u0442\\u0430\",\"\\u043f\\u0440\\u043e\\u0446\\u0435\\u043d\\u0442\\u043e\\u0432\",\"\\u0447\\u0442\\u043e\\u0431\\u044b\",\"\\u0434\\u043e\\u043b\\u043b\\u0430\\u0440\\u043e\\u0432\",\"\\u0433\\u043b\\u0430\\u0432\\u0430\",\"\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\",\"\\u044d\\u0442\\u043e\\u0433\\u043e\",\"\\u043e\\u0442\\u043c\\u0435\\u0442\\u0438\\u043b\",\"\\u0436\\u0435\",\"\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\",\"\\u0442\\u0430\\u043a\",\"\\u044f\\u043d\\u0432\\u0430\\u0440\\u044f\",\"\\u0438\\u043b\\u0438\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u044b\",\"\\u0440\\u0443\",\"\\u0442\\u043e\",\"\\u0435\\u0449\\u0435\",\"\\u043e\\u0431\\u043b\\u0430\\u0441\\u0442\\u0438\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u043c\",\"\\u0431\\u044b\\u043b\\u0430\",\"\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\\u0430\",\"\\u043e\\u043a\\u043e\\u043b\\u043e\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0438\\u043b\",\"\\u0444\\u0435\\u0432\\u0440\\u0430\\u043b\\u044f\",\"\\u043e\\u0434\\u043d\\u0430\\u043a\\u043e\",\"\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u0438\",\"\\u043c\\u043e\\u0436\\u0435\\u0442\",\"\\u0443\\u0436\\u0435\",\"\\u043e\\u0434\\u0438\\u043d\",\"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\",\"\\u0442\\u043e\\u043b\\u044c\\u043a\\u043e\",\"\\u043f\\u0440\\u043e\\u0446\\u0435\\u043d\\u0442\\u0430\",\"1\",\"10\",\"\\u0438\\u044e\\u043d\\u044f\",\"\\u0438\\u044e\\u043b\\u044f\",\"\\u043c\\u0430\\u044f\",\"\\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u043e\\u043d\\u043e\\u0432\",\"\\u043a\\u043e\\u0433\\u0434\\u0430\",\"\\u0430\\u043f\\u0440\\u0435\\u043b\\u044f\",\"\\u043f\\u0435\\u0440\\u0435\\u0434\\u0430\\u0435\\u0442\",\"\\u0435\\u0441\\u043b\\u0438\",\"\\u0431\\u0443\\u0434\\u0443\\u0442\",\"\\u0441\\u0430\\u0439\\u0442\\u0435\",\"\\u0434\\u0432\\u0430\",\"\\u043f\\u0440\\u043e\\u0442\\u0438\\u0432\",\"the\",\"20\",\"\\u043b\\u0435\\u043d\\u0442\\u044b\",\"\\u043d\\u0438\\u0445\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0430\\u0435\\u0442\\u0441\\u044f\",\"\\u0433\\u0434\\u0435\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0430\\u043b\\u043e\\u0441\\u044c\",\"\\u0440\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u0435\",\"\\u0432\\u0438\\u0434\\u0435\\u043e\",\"\\u0441\\u0435\\u043d\\u0442\\u044f\\u0431\\u0440\\u044f\",\"\\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u0435\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0435\",\"\\u043d\\u043e\\u0432\\u043e\\u0441\\u0442\\u0438\",\"\\u0432\\u043b\\u0430\\u0441\\u0442\\u0438\",\"\\u0441\\u0443\\u0434\",\"\\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u0441\\u044f\",\"\\u0430\\u0432\\u0433\\u0443\\u0441\\u0442\\u0430\",\"\\u043a\\u0440\\u043e\\u043c\\u0435\",\"15\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u043e\\u043d\\u0430\",\"\\u044f\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f\",\"\\u0442\\u044b\\u0441\\u044f\\u0447\\u0438\",\"\\u043c\\u0435\\u0436\\u0434\\u0443\",\"\\u0434\\u0435\\u043d\\u044c\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u0430\\u044f\",\"\\u0440\\u0438\\u0430\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\\u0430\",\"\\u043e\\u0442\\u043c\\u0435\\u0447\\u0430\\u0435\\u0442\\u0441\\u044f\",\"\\u043f\\u0443\\u0442\\u0438\\u043d\",\"\\u0431\\u044b\\u0442\\u044c\",\"\\u0434\\u0432\\u0443\\u0445\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0445\",\"\\u0441\\u0442\\u0430\\u043b\\u043e\",\"\\u0433\\u043e\\u0434\",\"2\",\"\\u0445\\u043e\\u0434\\u0435\",\"\\u0435\\u043c\\u0443\",\"\\u0441\\u0432\\u043e\\u0435\\u0439\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\",\"\\u0447\\u0435\\u0440\\u0435\\u0437\",\"\\u0431\\u0435\\u0437\\u043e\\u043f\\u0430\\u0441\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0442\\u0440\\u0438\",\"\\u0431\\u0435\\u0437\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0445\",\"\\u0447\\u0435\\u043c\",\"\\u0447\\u0438\\u0441\\u043b\\u0435\",\"30\",\"\\u0432\\u043b\\u0430\\u0434\\u0438\\u043c\\u0438\\u0440\",\"\\u0432\\u0441\\u0435\\u0433\\u043e\",\"\\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u0430\",\"\\u0441\\u0432\\u043e\\u044e\",\"\\u0435\\u0441\\u0442\\u044c\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u043e\\u043a\\u0442\\u044f\\u0431\\u0440\\u044f\",\"\\u0441\\u0440\\u0435\\u0434\\u0443\",\"\\u0432\\u0442\\u043e\\u0440\\u043d\\u0438\\u043a\",\"\\u043c\\u0438\\u0440\\u0430\",\"\\u043f\\u043e\\u043d\\u0435\\u0434\\u0435\\u043b\\u044c\\u043d\\u0438\\u043a\",\"\\u0434\\u043e\\u0431\\u0430\\u0432\\u0438\\u043b\",\"\\u0442\\u0430\\u0441\\u0441\",\"\\u0442\\u0435\\u0440\\u0440\\u0438\\u0442\\u043e\\u0440\\u0438\\u0438\",\"\\u043c\\u0435\\u0441\\u0442\\u043e\",\"12\",\"\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u044f\",\"\\u0441\\u0442\\u0430\\u043b\",\"\\u0447\\u0430\\u0441\\u0442\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0431\\u044b\",\"\\u0447\\u0435\\u0442\\u0432\\u0435\\u0440\\u0433\",\"\\u0434\\u043e\\u043c\\u0430\",\"\\u0438\\u0437\\u0434\\u0430\\u043d\\u0438\\u0435\",\"\\u0438\\u0437\\u0432\\u0435\\u0441\\u0442\\u043d\\u043e\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u044b\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0439\",\"\\u0441\\u0441\\u044b\\u043b\\u043a\\u043e\\u0439\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u0435\",\"\\u0440\\u0430\\u0437\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438\",\"\\u0434\\u0435\\u043a\\u0430\\u0431\\u0440\\u044f\",\"\\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u0438\",\"\\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\\u0430\",\"\\u044d\\u0442\\u043e\\u0442\",\"\\u0434\\u0435\\u043b\\u043e\",\"\\u043f\\u044f\\u0442\\u043d\\u0438\\u0446\\u0443\",\"2015\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u0430\\u0440\\u0434\\u0430\",\"14\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\\u0430\",\"3\",\"\\u043e\\u0442\\u043d\\u043e\\u0448\\u0435\\u043d\\u0438\\u0438\",\"\\u043d\\u0435\\u0433\\u043e\",\"\\u043c\\u043e\\u0433\\u0443\\u0442\",\"\\u0432\\u0441\\u0435\\u0445\",\"11\",\"\\u0441\\u043b\\u043e\\u0432\\u0430\",\"2018\",\"\\u0441\\u0440\\u0435\\u0434\\u0438\",\"\\u0442\\u0435\\u043c\",\"\\u0442\\u0440\\u0430\\u043c\\u043f\\u0430\",\"2014\",\"\\u0441\\u0435\\u0431\\u044f\",\"\\u0433\\u043b\\u0430\\u0432\\u044b\",\"\\u0440\\u0444\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u043e\\u0439\",\"\\u043f\\u043e\\u043a\\u0430\",\"\\u0442\\u0440\\u0430\\u043c\\u043f\",\"\\u0441\\u0438\\u0440\\u0438\\u0438\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0438\\u043b\\u0438\",\"4\",\"\\u043d\\u0435\\u0442\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u043e\\u0433\\u043e\",\"\\u043f\\u043e\\u0434\\u0447\\u0435\\u0440\\u043a\\u043d\\u0443\\u043b\",\"\\u0441\\u0432\\u044f\\u0437\\u0438\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u0438\\u0435\",\"\\u043d\\u043e\\u044f\\u0431\\u0440\\u044f\",\"25\",\"\\u043c\\u043e\\u0436\\u043d\\u043e\",\"\\u043f\\u0435\\u0440\\u0435\\u0434\",\"\\u043a\\u043e\\u043d\\u0446\\u0435\",\"\\u043e\\u0447\\u0435\\u043d\\u044c\",\"\\u0441\\u0435\\u0442\\u0438\",\"\\u0441\\u0435\\u0439\\u0447\\u0430\\u0441\",\"\\u043b\\u044e\\u0434\\u0435\\u0439\",\"\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0433\\u043e\",\"6\",\"\\u0440\\u0430\\u043c\\u043a\\u0430\\u0445\",\"\\u043f\\u0435\\u0440\\u0432\\u044b\\u0439\",\"18\",\"\\u0434\\u0440\\u0443\\u0433\\u0438\\u0445\",\"16\",\"\\u043d\\u0430\\u0434\",\"13\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0439\",\"7\",\"17\",\"\\u043c\\u043e\\u043c\\u0435\\u043d\\u0442\",\"5\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u043c\",\"\\u0442\\u0430\\u043c\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0438\\u0438\",\"\\u0443\\u043f\\u0440\\u0430\\u0432\\u043b\\u0435\\u043d\\u0438\\u044f\",\"\\u043a\\u043e\\u043c\\u0438\\u0442\\u0435\\u0442\\u0430\",\"\\u044d\\u0442\\u043e\\u0439\",\"\\u0438\\u043c\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\",\"\\u0441\\u043e\\u0433\\u043b\\u0430\\u0441\\u043d\\u043e\",\"\\u043d\\u0430\\u0441\\u0442\\u043e\\u044f\\u0449\\u0435\\u0435\",\"\\u043f\\u0438\\u0448\\u0435\\u0442\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u044b\",\"\\u0431\\u044b\\u0432\\u0448\\u0438\\u0439\",\"\\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\\u044b\",\"\\u043c\\u043d\\u0435\\u043d\\u0438\\u044e\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\\u0435\",\"24\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0435\\u043d\\u0438\\u0438\",\"\\u043d\\u0430\\u0437\\u0432\\u0430\\u043b\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0430\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u044b\",\"9\",\"\\u0440\\u0435\\u0441\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u0438\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u043b\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\\u0435\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u043e\\u0448\\u0435\\u043b\",\"\\u0442\\u043e\\u0442\",\"\\u0432\\u043e\\u043f\\u0440\\u043e\\u0441\",\"\\u0432\\u043c\\u0435\\u0441\\u0442\\u0435\",\"\\u0441\\u0442\\u0430\\u043b\\u0438\",\"\\u044d\\u0442\\u0438\",\"\\u0440\\u0430\\u0439\\u043e\\u043d\\u0435\",\"\\u0430\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\",\"19\",\"\\u0441\\u043c\\u0438\",\"23\",\"\\u0441\\u0435\\u0440\\u0433\\u0435\\u0439\",\"22\",\"\\u043f\\u043e\\u0447\\u0442\\u0438\",\"\\u0434\\u0435\\u0442\\u0435\\u0439\",\"\\u043f\\u044f\\u0442\\u044c\",\"21\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u0435\",\"\\u0430\\u0433\\u0435\\u043d\\u0442\\u0441\\u0442\\u0432\\u043e\",\"\\u0434\\u043c\\u0438\\u0442\\u0440\\u0438\\u0439\",\"\\u043e\\u0434\\u043d\\u043e\\u0439\",\"\\u043e\\u0434\\u043d\\u043e\\u0433\\u043e\",\"\\u0441\\u043b\\u0443\\u0447\\u0430\\u0435\",\"\\u043c\\u0438\\u043b\\u043b\\u0438\\u0430\\u0440\\u0434\\u043e\\u0432\",\"twitter\",\"\\u0437\\u0430\\u044f\\u0432\\u0438\\u043b\\u0430\",\"\\u0447\\u0430\\u0441\\u0442\\u044c\",\"\\u043e\\u0442\\u043c\\u0435\\u0447\\u0430\\u0435\\u0442\",\"\\u0442\\u043e\\u0433\\u0434\\u0430\",\"8\",\"\\u043f\\u043e\\u0433\\u0438\\u0431\\u043b\\u0438\",\"\\u043c\\u0432\\u0434\",\"\\u0436\\u0438\\u0437\\u043d\\u0438\",\"\\u043c\\u0435\\u0441\\u0442\\u0435\",\"\\u0441\\u0432\\u043e\\u0435\\u043c\",\"\\u0447\\u0435\\u0442\\u044b\\u0440\\u0435\",\"\\u0447\\u0430\\u0441\\u0442\\u0438\",\"\\u0432\\u0435\\u0434\\u043e\\u043c\\u0441\\u0442\\u0432\\u0430\",\"\\u0441\\u043e\\u0442\\u0440\\u0443\\u0434\\u043d\\u0438\\u043a\\u0438\",\"\\u043d\\u0430\\u0445\\u043e\\u0434\\u0438\\u0442\\u0441\\u044f\",\"\\u043f\\u043e\\u0440\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u0447\\u0435\\u0433\\u043e\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044e\",\"facebook\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0435\",\"\\u0441\\u043e\\u043e\\u0431\\u0449\\u0438\\u043b\\u0430\",\"\\u0438\\u0441\\u0442\\u043e\\u0447\\u043d\\u0438\\u043a\",\"27\",\"\\u0437\\u0430\\u044f\\u0432\\u0438\\u043b\\u0438\",\"\\u043d\\u0438\",\"28\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0435\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u0430\",\"26\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\\u043d\",\"\\u0441\\u0432\\u043e\\u0438\\u0445\",\"\\u0437\\u0430\\u0442\\u0435\\u043c\",\"\\u043d\\u0430\\u0441\",\"100\",\"\\u0442\\u0430\\u043a\\u0438\\u043c\",\"\\u0441\\u0442\\u0430\\u043b\\u0430\",\"\\u0434\\u043d\\u044f\",\"\\u0443\\u0434\\u0430\\u043b\\u043e\\u0441\\u044c\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u0435\",\"\\u043f\\u0440\\u0438\\u0432\\u043e\\u0434\\u0438\\u0442\",\"\\u0434\\u043e\\u043b\\u0436\\u0435\\u043d\",\"\\u043b\\u0438\",\"\\u043e\\u0431\\u0440\\u0430\\u0437\\u043e\\u043c\",\"\\u0434\\u0440\\u0443\\u0433\\u0438\\u0435\",\"\\u0443\\u0433\\u043e\\u043b\\u043e\\u0432\\u043d\\u043e\\u0435\",\"\\u0434\\u043e\\u043c\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442\",\"\\u0441\\u0447\\u0438\\u0442\\u0430\\u0435\\u0442\",\"\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432\",\"\\u0430\\u0433\\u0435\\u043d\\u0442\\u0441\\u0442\\u0432\\u0430\",\"\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u044f\",\"\\u0442\\u0435\\u0447\\u0435\\u043d\\u0438\\u0435\",\"\\u0442\\u0440\\u0435\\u0445\",\"\\u0432\\u0442\\u043e\\u0440\\u043e\\u0439\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\\u0430\",\"\\u043d\\u0430\\u043f\\u0438\\u0441\\u0430\\u043b\",\"\\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044e\",\"\\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\",\"\\u0434\\u0438\\u0440\\u0435\\u043a\\u0442\\u043e\\u0440\",\"\\u043a\\u0430\\u0447\\u0435\\u0441\\u0442\\u0432\\u0435\",\"\\u0440\\u0435\\u0433\\u0438\\u043e\\u043d\\u0430\",\"\\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439\",\"\\u0441\\u0432\\u043e\\u0438\",\"news\",\"\\u043d\\u043e\\u0432\\u044b\\u0445\",\"\\u043d\\u043e\\u0432\\u044b\\u0439\",\"\\u0434\\u0435\\u043b\\u0430\",\"\\u0441\\u0432\\u043e\\u0435\\u0433\\u043e\",\"\\u0441\\u043e\\u0432\\u0435\\u0442\\u0430\",\"\\u043c\\u0438\\u0434\",\"\\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0435\\u0439\",\"\\u043a\\u0442\\u043e\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u043b\\u0438\",\"\\u0438\\u0434\\u0435\\u0442\",\"\\u0434\\u0430\\u0436\\u0435\",\"\\u0435\\u0432\\u0440\\u043e\",\"50\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u0432\\u044c\\u044e\",\"\\u0438\\u043d\\u0446\\u0438\\u0434\\u0435\\u043d\\u0442\",\"\\u0431\\u044b\\u0432\\u0448\\u0435\\u0433\\u043e\",\"\\u0436\\u0435\\u043d\\u0449\\u0438\\u043d\\u0430\",\"\\u0436\\u0438\\u0442\\u0435\\u043b\\u0435\\u0439\",\"\\u0432\\u043d\\u0438\\u043c\\u0430\\u043d\\u0438\\u0435\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0435\",\"\\u043b\\u044e\\u0434\\u0438\",\"\\u0432\\u043f\\u0435\\u0440\\u0432\\u044b\\u0435\",\"\\u0432\\u0440\\u0435\\u043c\\u0435\\u043d\\u0438\",\"\\u043b\\u0438\\u0434\\u0435\\u0440\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u0438\",\"\\u043f\\u043e\\u0441\\u0442\",\"\\u043c\\u0430\\u0440\\u0442\\u0435\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0438\\u044f\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u044b\",\"\\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u044b\",\"\\u043f\\u043e\\u044f\\u0441\\u043d\\u0438\\u043b\",\"\\u043e\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u043e\\u0432\\u0430\\u043d\\u043e\",\"\\u0434\\u043d\\u0435\\u0439\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0443\",\"\\u0432\\u0435\\u0440\\u0441\\u0438\\u0438\",\"\\u043f\\u0430\\u0440\\u0442\\u0438\\u0438\",\"\\u043c\\u0435\\u043d\\u044f\",\"\\u0434\\u0435\\u043a\\u0430\\u0431\\u0440\\u0435\",\"\\u043e\\u0442\\u043c\\u0435\\u0442\\u0438\\u043b\\u0438\",\"\\u043f\\u043e\\u043c\\u043e\\u0449\\u0438\",\"29\",\"\\u0438\\u0433\",\"\\u0438\\u0437\\u0434\\u0430\\u043d\\u0438\\u044f\",\"\\u0447\\u0438\\u0441\\u043b\\u043e\",\"\\u043c\\u0438\\u0440\\u0435\",\"\\u0433\\u0435\\u0440\\u043c\\u0430\\u043d\\u0438\\u0438\",\"\\u043f\\u0435\\u0441\\u043a\\u043e\\u0432\",\"\\u043e\\u043e\\u043d\",\"\\u0435\\u0439\",\"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0438\\u0439\",\"\\u043f\\u0440\\u043e\\u0448\\u043b\\u043e\\u0433\\u043e\",\"\\u044f\\u043d\\u0432\\u0430\\u0440\\u0435\",\"\\u0441\\u043c\\u0435\\u0440\\u0442\\u0438\",\"\\u043f\\u043e\\u0440\\u044f\\u0434\\u043a\\u0430\",\"\\u0444\\u0435\\u0434\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438\",\"\\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\",\"\\u043e\\u0431\\u043d\\u0430\\u0440\\u0443\\u0436\\u0438\\u043b\\u0438\",\"\\u0434\\u0432\\u0435\",\"\\u0434\\u0435\\u043d\\u044c\\u0433\\u0438\",\"\\u043f\\u043e\\u043c\\u043e\\u0449\\u044c\\u044e\",\"\\u0441\\u0431\\u043e\\u0440\\u043d\\u043e\\u0439\",\"\\u043f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u044b\",\"\\u0434\\u0435\\u043f\\u0443\\u0442\\u0430\\u0442\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0440\\u0435\\u043b\\u0438\\u0437\\u0435\",\"\\u043e\\u0447\\u0435\\u0440\\u0435\\u0434\\u044c\",\"\\u0437\\u0430\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\\u0438\",\"\\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\",\"\\u0438\\u0442\\u043e\\u0433\\u0430\\u043c\",\"\\u0433\\u0430\\u0437\\u0435\\u0442\\u0430\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u0444\\u0430\\u043a\\u0441\",\"\\u0434\\u0435\\u043b\",\"\\u0441\\u0443\\u0434\\u0430\",\"\\u0440\\u0430\\u0437\\u0432\\u0438\\u0442\\u0438\\u044f\",\"\\u0441\\u043b\\u0443\\u0436\\u0431\\u044b\",\"\\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\\u0430\",\"\\u043c\\u0435\\u0441\\u0442\\u0430\",\"\\u0441\\u0438\\u043b\",\"\\u0443\\u0447\\u0435\\u043d\\u044b\\u0435\",\"\\u043f\\u0440\\u043e\\u0439\\u0434\\u0435\\u0442\",\"\\u043a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432\",\"\\u0441\\u043e\\u0442\\u0440\\u0443\\u0434\\u043d\\u0438\\u043a\\u043e\\u0432\",\"\\u043a\\u043e\\u0440\\u0440\\u0435\\u0441\\u043f\\u043e\\u043d\\u0434\\u0435\\u043d\\u0442\",\"\\u0446\\u0435\\u043d\\u0442\\u0440\\u0435\",\"\\u0432\\u043e\\u0441\\u043a\\u0440\\u0435\\u0441\\u0435\\u043d\\u044c\\u0435\",\"\\u0447\\u0430\\u0441\\u043e\\u0432\",\"\\u043c\\u043d\\u0435\",\"\\u0444\\u0435\\u0432\\u0440\\u0430\\u043b\\u0435\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u0438\\u0446\\u0435\",\"\\u043c\\u043e\\u0441\\u043a\\u043e\\u0432\\u0441\\u043a\\u043e\\u0439\",\"\\u043d\\u043e\\u0432\\u043e\\u0433\\u043e\",\"\\u043f\\u043e\\u044d\\u0442\\u043e\\u043c\\u0443\",\"\\u043d\\u043e\\u0432\\u043e\\u0439\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u043e\\u0433\\u043e\",\"\\u043d\\u043e\\u0432\\u043e\\u0441\\u0442\\u0435\\u0439\",\"\\u043a\\u0440\\u044b\\u043c\\u0430\",\"\\u0438\\u043c\\u0435\\u043d\\u043d\\u043e\",\"\\u044d\\u0442\\u0443\",\"\\u043c\\u0435\\u043d\\u0435\\u0435\",\"\\u043a\\u043d\\u0434\\u0440\",\"\\u0440\\u0435\\u0447\\u044c\",\"\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e\\u0441\\u0442\\u044c\",\"\\u0442\\u0430\\u043a\\u043e\\u0435\",\"\\u0437\\u0430\\u044f\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u043e\\u043b\\u043d\\u043e\\u0441\\u0442\\u044c\\u044e\",\"\\u043d\\u0430\\u0437\\u0430\\u0434\",\"\\u043a\\u0440\\u044b\\u043c\",\"\\u0444\\u0440\\u0430\\u043d\\u0446\\u0438\\u0438\",\"\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0438\",\"\\u0430\\u0434\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\\u0430\\u0446\\u0438\\u0438\",\"\\u043d\\u0435\\u043c\",\"\\u043f\\u0443\\u0442\\u0438\\u043d\\u0430\",\"\\u0442\\u0430\\u043a\\u0438\\u0435\",\"reuters\",\"\\u0444\\u043e\\u0442\\u043e\",\"\\u0431\\u0430\\u043d\\u043a\\u0430\",\"\\u043d\\u0435\\u0435\",\"\\u044d\\u0442\\u0438\\u0445\",\"\\u0441\\u0432\\u043e\\u0439\",\"\\u043d\\u043e\\u0432\\u044b\\u0435\",\"\\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0438\\u043b\",\"\\u043e\\u0434\\u043d\\u0430\",\"\\u043e\\u0431\\u0432\\u0438\\u043d\\u0435\\u043d\\u0438\\u044f\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u0443\\u044e\",\"\\u0434\\u043e\\u043d\\u0431\\u0430\\u0441\\u0441\\u0435\",\"\\u0442\\u0435\\u043b\\u0435\\u043a\\u0430\\u043d\\u0430\\u043b\",\"\\u043f\\u043e\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u0443\",\"\\u043b\\u0435\\u043d\\u0442\\u0435\",\"\\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438\",\"\\u043d\\u0435\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435\",\"\\u0443\\u043a\",\"40\",\"\\u043d\\u043e\\u044f\\u0431\\u0440\\u0435\",\"\\u0442\\u0430\\u043a\\u0438\\u0445\",\"\\u044f\\u043a\\u043e\\u0431\\u044b\",\"\\u043a\\u043e\\u043c\\u0430\\u043d\\u0434\\u044b\",\"\\u0432\\u0435\\u043b\\u0438\\u043a\\u043e\\u0431\\u0440\\u0438\\u0442\\u0430\\u043d\\u0438\\u0438\",\"\\u043e\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u043e\\u0432\\u0430\\u043b\",\"\\u0438\\u043c\\u0435\\u043d\\u0438\",\"\\u044d\\u0442\\u0438\\u043c\",\"31\",\"\\u043e\\u0440\\u0443\\u0436\\u0438\\u044f\",\"\\u0441\\u043f\\u0438\\u0441\\u043e\\u043a\",\"\\u0446\\u0435\\u043d\\u0442\\u0440\\u0430\",\"\\u0433\\u043e\\u0441\\u0434\\u0443\\u043c\\u044b\",\"\\u0448\\u0435\\u0441\\u0442\\u044c\",\"\\u0432\\u044b\\u0431\\u043e\\u0440\\u044b\",\"\\u043d\\u0435\\u0439\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\\u0438\",\"\\u043f\\u0440\\u043e\\u0441\\u0442\\u043e\",\"\\u0430\\u043d\\u0434\\u0440\\u0435\\u0439\",\"\\u0441\\u0430\\u043c\",\"\\u0441\\u043b\\u0435\\u0434\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0433\\u043e\",\"\\u0441\\u0440\\u043e\\u043a\",\"\\u043f\\u0435\\u0440\\u0438\\u043e\\u0434\",\"\\u0443\\u043b\\u0438\\u0446\\u0435\",\"\\u043d\\u0438\\u043c\",\"\\u0438\\u043c\\u0435\\u0435\\u0442\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\",\"\\u0442\\u0430\\u043a\\u043e\\u0439\",\"\\u043d\\u0443\\u0436\\u043d\\u043e\",\"\\u0442\\u0443\\u0440\\u0446\\u0438\\u0438\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0441\\u0435\\u043a\\u0440\\u0435\\u0442\\u0430\\u0440\\u044c\",\"\\u043e\\u0431\\u043e\\u0440\\u043e\\u043d\\u044b\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0430\",\"\\u0430\\u043f\\u0440\\u0435\\u043b\\u0435\",\"\\u0447\\u0435\\u043c\\u043f\\u0438\\u043e\\u043d\\u0430\\u0442\\u0430\",\"\\u043c\\u0435\\u0440\\u044b\",\"\\u0442\\u0435\\u0445\",\"\\u043f\\u0440\\u0430\\u0432\\u0430\",\"\\u043e\\u0444\\u0438\\u0446\\u0438\\u0430\\u043b\\u044c\\u043d\\u044b\\u0439\",\"\\u043a\\u0438\\u0435\\u0432\",\"\\u0434\\u0435\\u043b\\u0443\",\"\\u043f\\u0440\\u0438\\u0447\\u0438\\u043d\\u043e\\u0439\",\"\\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u0438\",\"\\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0445\\u0440\\u0430\\u043d\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445\",\"\\u0438\\u043d\\u043e\\u0441\\u0442\\u0440\\u0430\\u043d\\u043d\\u044b\\u0445\",\"\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0435\\u0439\",\"\\u043f\\u043e\\u0442\\u043e\\u043c\\u0443\",\"\\u0432\\u043e\\u0437\\u0431\\u0443\\u0436\\u0434\\u0435\\u043d\\u043e\",\"\\u043f\\u043e\\u043c\\u0438\\u043c\\u043e\",\"\\u0441\\u043e\\u0431\\u043e\\u0439\",\"\\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u0438\",\"\\u043a\\u0438\\u0435\\u0432\\u0435\",\"2016-\\u0433\\u043e\",\"\\u043f\\u0440\\u0438\\u043c\\u0435\\u0440\\u043d\\u043e\",\"\\u0441\\u0434\\u0435\\u043b\\u0430\\u0442\\u044c\",\"\\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u043e\",\"\\u0441\\u0443\\u0431\\u0431\\u043e\\u0442\\u0443\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u043e\\u0448\\u043b\\u043e\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u0430\",\"\\u0441\\u0435\\u043d\\u0442\\u044f\\u0431\\u0440\\u0435\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\",\"\\u0441\\u043b\\u0435\\u0434\\u0441\\u0442\\u0432\\u0438\\u044f\",\"\\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u044f\",\"\\u043d\\u0430\\u0448\\u043b\\u0438\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\",\"\\u0440\\u043e\\u0441\\u0442\",\"\\u043c\\u0430\\u0435\",\"\\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f\",\"\\u0441\\u0430\\u043c\\u044b\\u0445\",\"\\u0432\\u044b\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u0439\",\"\\u043c\\u0435\\u0436\\u0434\\u0443\\u043d\\u0430\\u0440\\u043e\\u0434\\u043d\\u043e\\u0433\\u043e\",\"\\u043d\\u043e\\u0447\\u044c\",\"\\u0441\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u0438\\u0438\",\"\\u043f\\u044f\\u0442\\u0438\",\"\\u0440\\u0435\\u0434\\u0430\\u043a\\u0446\\u0438\\u044e\",\"\\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0438\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043b\\u0438\\u0448\\u044c\",\"\\u043f\\u043e\\u0437\\u0434\\u043d\\u0435\\u0435\",\"\\u0440\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u044b\",\"\\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u043a\\u043e\\u043b\\u0438\\u0447\\u0435\\u0441\\u0442\\u0432\\u043e\",\"\\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u0430\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0430\\u044f\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\\u0435\\u0432\",\"\\u0440\\u0435\\u0431\\u0435\\u043d\\u043a\\u0430\",\"\\u0432\\u043e\\u0435\\u043d\\u043d\\u044b\\u0445\",\"\\u0434\\u0440\\u0443\\u0433\\u043e\\u0439\",\"\\u0441\\u0432\\u043e\\u0435\",\"\\u043f\\u043e\\u0441\\u0442\\u0440\\u0430\\u0434\\u0430\\u043b\\u0438\",\"ru\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u043e\\u0432\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u0435\\u0439\",\"\\u0432\\u043e\\u0439\\u043d\\u044b\",\"\\u0440\\u044f\\u0434\",\"\\u043b\\u0438\\u0446\",\"\\u0447\\u0435\\u0442\\u044b\\u0440\\u0435\\u0445\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u043d\\u0438\\u043a\\u043e\\u0432\",\"\\u0435\\u0441\",\"\\u0441\\u0447\\u0438\\u0442\\u0430\\u044e\\u0442\",\"\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u0439\",\"\\u044d\\u043a\\u0441\\u043f\\u0435\\u0440\\u0442\\u044b\",\"\\u0441\\u0430\\u043d\\u043a\\u0446\\u0438\\u0438\",\"\\u043d\\u0435\\u043e\\u0431\\u0445\\u043e\\u0434\\u0438\\u043c\\u043e\",\"\\u0441\\u0435\\u0431\\u0435\",\"\\u043e\\u0434\\u043d\\u0438\\u043c\",\"\\u043d\\u0430\\u0437\\u0432\\u0430\\u043b\\u0438\",\"\\u0435\\u0432\\u0440\\u043e\\u043f\\u044b\",\"\\u044d\\u0442\\u0430\",\"\\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u044c\",\"\\u0441\\u0442\\u0430\\u043d\\u0435\\u0442\",\"\\u043d\\u0430\\u043c\",\"\\u0434\\u043e\\u043d\\u0430\\u043b\\u044c\\u0434\\u0430\",\"\\u043e\\u043a\\u0442\\u044f\\u0431\\u0440\\u0435\",\"\\u0441\\u0430\\u043c\\u044b\\u043c\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0441\\u043b\\u0443\\u0436\\u0431\\u0435\",\"\\u0436\\u0435\\u043d\\u0449\\u0438\\u043d\",\"\\u0434\\u043e\\u043a\\u0443\\u043c\\u0435\\u043d\\u0442\",\"\\u043e\\u0442\\u043d\\u043e\\u0448\\u0435\\u043d\\u0438\\u044f\",\"\\u043e\\u0442\\u043a\\u0430\\u0437\\u0430\\u043b\\u0441\\u044f\",\"\\u043f\\u0440\\u0435\\u0434\\u0441\\u0435\\u0434\\u0430\\u0442\\u0435\\u043b\\u044c\",\"\\u043c\\u0438\\u043d\\u043e\\u0431\\u043e\\u0440\\u043e\\u043d\\u044b\",\"\\u043e\\u0442\\u043c\\u0435\\u0442\\u0438\\u043b\\u0430\",\"\\u0440\\u043e\\u043b\\u0438\\u043a\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u0435\",\"s\",\"\\u0436\\u0435\\u043d\\u0449\\u0438\\u043d\\u044b\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u043b\",\"\\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u0438\\u0445\",\"\\u043f\\u0435\\u0440\\u0432\\u043e\\u0433\\u043e\",\"2013\",\"\\u043f\\u0435\\u0440\\u0432\\u043e\\u043c\",\"\\u0436\\u0438\\u0442\\u0435\\u043b\\u0438\",\"...\",\"\\u043f\\u043b\\u0430\\u043d\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044f\",\"\\u0432\\u0441\\u0442\\u0440\\u0435\\u0447\\u0430\",\"\\u0442\\u0435\\u043f\\u0435\\u0440\\u044c\",\"\\u043e\\u0431\\u044a\\u044f\\u0432\\u0438\\u043b\",\"\\u043e\\u043f\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438\",\"\\u0430\\u043b\\u0435\\u043a\\u0441\\u0435\\u0439\",\"\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\\u0430\",\"\\u0432\\u044b\\u0431\\u043e\\u0440\\u0430\\u0445\",\"\\u0441\\u0430\\u043c\\u043e\\u043b\\u0435\\u0442\",\"\\u0430\\u043a\\u0446\\u0438\\u0438\",\"daily\",\"\\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044f\",\"\\u043f\\u043e\\u0437\\u0436\\u0435\",\"\\u0434\\u043e\\u043c\\u0435\",\"\\u0441\\u0447\\u0435\\u0442\",\"\\u043d\\u0435\\u0441\\u043c\\u043e\\u0442\\u0440\\u044f\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\\u0438\",\"\\u0432\\u043b\\u0430\\u0434\\u0438\\u043c\\u0438\\u0440\\u0430\",\"\\u0441\\u043f\\u0435\\u0446\\u0438\\u0430\\u043b\\u0438\\u0441\\u0442\\u044b\",\"\\u0441\\u0447\\u0435\\u0442\\u043e\\u043c\",\"\\u0440\\u0430\\u0437\\u043c\\u0435\\u0440\\u0435\",\"\\u0441\\u0432\\u043e\\u0438\\u043c\",\"\\u0441\\u0430\\u043d\\u043a\\u0446\\u0438\\u0439\",\"\\u0434\\u043d\\u0440\",\"\\u0440\\u044b\\u043d\\u043a\\u0435\",\"\\u0434\\u0432\\u043e\\u0435\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u043b\\u0430\",\"\\u0437\\u0430\\u0434\\u0435\\u0440\\u0436\\u0430\\u043d\",\"instagram\",\"\\u043f\\u0440\\u0438\\u0437\\u0432\\u0430\\u043b\",\"\\u043f\\u0440\\u0438\\u043c\",\"\\u0430\\u043a\\u0442\\u0435\\u0440\",\"\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0439\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\\u044b\",\"\\u043c\\u043d\\u043e\\u0433\\u0438\\u0435\",\"200\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u043e\\u0439\",\"\\u0438\\u044e\\u043d\\u0435\",\"\\u0433\\u043e\\u0434\\u044b\",\"\\u043c\\u0430\\u0448\\u0438\\u043d\\u044b\",\"\\u0437\\u0430\\u043c\\u0435\\u0441\\u0442\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u043d\\u0438\\u0447\\u0435\\u0433\\u043e\",\"\\u0440\\u0435\\u0433\\u0438\\u043e\\u043d\\u0435\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u0438\\u043d\\u0441\\u0442\\u0432\\u043e\",\"\\u0432\\u0438\\u0434\\u0435\",\"\\u043d\\u0430\\u0445\\u043e\\u0434\\u044f\\u0442\\u0441\\u044f\",\"\\u0441\\u043a\\u0430\\u0437\\u0430\\u043b\\u0430\",\"\\u0430\\u0440\\u043c\\u0438\\u0438\",\"\\u0432\\u0441\\u0435\\u043c\",\"\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\\u043e\\u043c\",\"\\u0440\\u0430\\u0441\\u0441\\u043b\\u0435\\u0434\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435\",\"\\u0434\\u043e\\u043d\\u0430\\u043b\\u044c\\u0434\",\"\\u043e\\u0434\\u043d\\u043e\\u043c\",\"\\u0432\\u043b\\u0430\\u0441\\u0442\\u0435\\u0439\",\"\\u0441\\u043e\\u0447\\u0438\",\"\\u0438\\u0433\\u0440\\u044b\",\"\\u043f\\u0440\\u0430\\u0432\\u043e\",\"\\u043f\\u043e\\u0440\\u0442\\u0430\\u043b\",\"\\u043d\\u0430\\u0447\\u0430\\u043b\",\"\\u043f\\u043e\\u043c\\u043e\\u0449\\u044c\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0438\\u0445\",\"\\u043d\\u0430\\u0442\\u043e\",\"\\u0432\\u043e\\u0448\\u043b\\u0438\",\"\\u043f\\u0435\\u0440\\u0432\\u043e\\u0439\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0435\\u0439\\u0441\\u043a\\u0438\\u0435\",\"\\u043b\\u0438\\u0434\\u0435\\u0440\\u0430\",\"\\u0433\\u0430\\u0437\\u0430\",\"\\u0440\\u0435\\u0433\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0433\\u043e\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\\u0435\",\"\\u0438\\u044e\\u043b\\u0435\",\"\\u0440\\u0430\\u0437\\u0430\",\"\\u043f\\u0440\\u043e\\u0432\\u0435\\u0434\\u0435\\u043d\\u0438\\u044f\",\"\\u0444\\u0430\\u043a\\u0442\\u0443\",\"\\u043c\\u0438\\u043d\\u0443\\u0442\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u043b\\u0438\",\"\\u0441\\u0443\\u043c\\u043c\\u0443\",\"\\u043f\\u043e\\u043b\\u0438\\u0442\\u0438\\u043a\\u0438\",\"\\u043e\\u043a\\u0430\\u0437\\u0430\\u043b\\u0441\\u044f\",\"\\u0432\\u043e\\u0435\\u043d\\u043d\\u044b\\u0435\",\"\\u0434\\u0432\\u0438\\u0436\\u0435\\u043d\\u0438\\u044f\",\"\\u043c\\u0430\\u0442\\u0447\\u0435\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u043e\\u0433\\u043e\",\"\\u0434\\u043d\\u0435\\u043c\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u043c\",\"\\u0441\\u0432\\u043e\\u0431\\u043e\\u0434\\u044b\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\\u043e\\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\",\"\\u043c\\u043e\\u0434\\u0435\\u043b\\u044c\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u0442\\u044c\",\"\\u043d\\u0430\\u0438\\u0431\\u043e\\u043b\\u0435\\u0435\",\"\\u043c\\u043e\\u0434\\u0435\\u043b\\u0438\",\"\\u0446\\u0431\",\"\\u043f\\u0440\\u043e\\u043a\\u043e\\u043c\\u043c\\u0435\\u043d\\u0442\\u0438\\u0440\\u043e\\u0432\\u0430\\u043b\",\"\\u044d\\u0442\\u043e\\u043c\\u0443\",\"youtube\",\"\\u043c\\u043d\\u043e\\u0433\\u043e\",\"\\u044f\\u0432\\u043b\\u044f\\u044e\\u0442\\u0441\\u044f\",\"\\u043a\\u0430\\u0436\\u0434\\u044b\\u0439\",\"\\u0442\\u043e\\u043d\\u043d\",\"00\",\"\\u043a\\u043e\\u043d\\u0446\\u0430\",\"\\u0444\\u0438\\u043b\\u044c\\u043c\\u0430\",\"\\u0437\\u0434\\u0430\\u043d\\u0438\\u044f\",\"\\u043f\\u0440\\u043e\\u0432\\u0438\\u043d\\u0446\\u0438\\u0438\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\",\"\\u043f\\u043e\\u0441\\u0442\\u0443\\u043f\\u0438\\u0432\\u0448\\u0435\\u043c\",\"\\u043e\\u0434\\u0435\\u0436\\u0434\\u044b\",\"\\u043d\\u0435\\u043e\\u0434\\u043d\\u043e\\u043a\\u0440\\u0430\\u0442\\u043d\\u043e\",\"\\u0441\\u0435\\u0432\\u0435\\u0440\\u043d\\u043e\\u0439\",\"\\u0433\\u043e\\u0434\\u0430\\u0445\",\"\\u0430\\u0432\\u0433\\u0443\\u0441\\u0442\\u0435\",\"\\u043f\\u0440\\u043e\\u0432\\u0435\\u0441\\u0442\\u0438\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u043c\",\"\\u043f\\u0440\\u0435\\u0441\\u0441-\\u0441\\u043b\\u0443\\u0436\\u0431\\u0430\",\"\\u0431\\u043b\\u0430\\u0433\\u043e\\u0434\\u0430\\u0440\\u044f\",\"\\u0441\\u0435\\u043c\\u044c\",\"\\u0432\\u043e\\u0441\\u0435\\u043c\\u044c\",\"\\u043c\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u0441\\u043a\\u043e\\u043d\\u0447\\u0430\\u043b\\u0441\\u044f\",\"\\u043c\\u0435\\u0440\\u043e\\u043f\\u0440\\u0438\\u044f\\u0442\\u0438\\u044f\",\"\\u0443\\u0442\\u043e\\u0447\\u043d\\u0438\\u043b\",\"60\",\"\\u0433\\u043b\\u0430\\u0432\\u043d\\u044b\\u0439\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0430\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\",\"\\u0440\\u0430\\u043a\\u0435\\u0442\\u044b\",\"\\u0441\\u0442\\u043e\\u043b\\u0438\\u0446\\u044b\",\"\\u043e\\u0431\\u044a\\u0435\\u043c\",\"\\u0444\\u043e\\u043d\\u0434\\u0430\",\"\\u0444\\u0438\\u043b\\u044c\\u043c\",\"\\u0436\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0438\\u0435\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0442\\u044c\",\"\\u0441\\u0430\\u043c\\u043e\\u043b\\u0435\\u0442\\u0430\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0435\",\"\\u0441\\u043e\\u0441\\u0442\\u043e\\u0438\\u0442\\u0441\\u044f\",\"\\u043a\\u043b\\u0443\\u0431\\u0430\",\"\\u043c\\u0435\\u0436\\u0434\\u0443\\u043d\\u0430\\u0440\\u043e\\u0434\\u043d\\u043e\\u0439\",\"\\u0441\\u0442\\u0440\\u0430\\u043d\\u0443\",\"\\u0441\\u043a\\u0440\",\"\\u043f\\u0440\\u0438\\u0437\\u043d\\u0430\\u043b\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\",\"\\u043d\\u0430\\u0441\\u0435\\u043b\\u0435\\u043d\\u0438\\u044f\",\"\\u0441\\u0442\\u043e\\u043b\\u0438\\u0446\\u0435\",\"\\u043a\\u043e\\u043d\\u0444\\u043b\\u0438\\u043a\\u0442\\u0430\",\"\\u043f\\u043e\\u043e\\u0431\\u0435\\u0449\\u0430\\u043b\",\"\\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430\",\"500\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\\u0430\",\"\\u0431\\u0430\\u043d\\u043a\",\"\\u0446\\u0435\\u043b\\u044c\\u044e\",\"2012\",\"\\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u044b\",\"\\u0443\\u0440\\u043e\\u0432\\u043d\\u0435\",\"\\u0443\\u043c\\u0435\\u0440\",\"\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u043a\\u0432\\u0430\\u0434\\u0440\\u0430\\u0442\\u043d\\u044b\\u0445\",\"\\u043d\\u0430\\u043f\\u0440\\u0438\\u043c\\u0435\\u0440\",\"\\u0432\\u0435\\u0447\\u0435\\u0440\\u043e\\u043c\",\"\\u043b\\u0438\\u043d\\u0438\\u0438\",\"\\u043f\\u0430\\u0441\\u0441\\u0430\\u0436\\u0438\\u0440\\u043e\\u0432\",\"\\u0441\\u0442\\u0440\\u043e\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u0434\\u0435\\u043d\\u0435\\u0433\",\"\\u0444\\u0441\\u0431\",\"\\u043d\\u0435\\u0444\\u0442\\u0438\",\"\\u0441\\u0440\\u0430\\u0437\\u0443\",\"\\u0432\\u044b\\u0431\\u043e\\u0440\\u043e\\u0432\",\"\\u0438\\u043c\\u044f\",\"\\u0434\\u0430\\u043d\\u043d\\u044b\\u0445\",\"\\u0431\\u0440\\u0435\\u043d\\u0434\\u0430\",\"\\u0436\\u0438\\u0437\\u043d\\u044c\",\"\\u0436\\u0438\\u043b\\u044c\\u044f\",\"\\u043d\\u0438\\u043a\\u0442\\u043e\",\"\\u0441\\u0440\\u0430\\u0432\\u043d\\u0435\\u043d\\u0438\\u044e\",\"\\u0432\\u044b\\u0440\\u0430\\u0437\\u0438\\u043b\",\"\\u043e\\u043a\\u0430\\u0437\\u0430\\u043b\\u0438\\u0441\\u044c\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u043e\\u0439\",\"\\u0432\\u043a\\u043b\\u044e\\u0447\\u0430\\u044f\",\"\\u043a\\u043e\\u043c\\u0438\\u0442\\u0435\\u0442\",\"\\u0440\\u0443\\u043a\\u043e\\u0432\\u043e\\u0434\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u0438\\u044f\",\"\\u043f\\u0440\\u0435\\u0441\\u0442\\u0443\\u043f\\u043b\\u0435\\u043d\\u0438\\u044f\",\"\\u043e\\u043d\\u043e\",\"\\u043a\\u0438\\u0435\\u0432\\u0430\",\"\\u0442\\u0443\\u0440\\u0438\\u0441\\u0442\\u043e\\u0432\",\"\\u0448\\u0442\\u0430\\u0442\",\"\\u043f\\u0440\\u043e\\u0438\\u0441\\u0448\\u0435\\u0441\\u0442\\u0432\\u0438\\u044f\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0435\",\"\\u0434\\u043e\\u043d\\u0435\\u0446\\u043a\\u043e\\u0439\",\"\\u0442\\u0435\\u043b\\u0435\\u043a\\u0430\\u043d\\u0430\\u043b\\u0430\",\"\\u0441\\u0442\\u043e\\u0438\\u0442\",\"\\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0430\",\"\\u0431\\u043e\\u0435\\u0432\\u0438\\u043a\\u043e\\u0432\",\"\\u0440\\u0435\\u0448\\u0438\\u043b\",\"\\u0441\\u043c\\u043e\\u0433\\u0443\\u0442\",\"\\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0439\",\"\\u043c\\u0430\\u0440\\u043a\\u0438\",\"\\u0440\\u0435\\u0436\\u0438\\u043c\\u0430\",\"\\u0441\\u043f\\u0443\\u0441\\u0442\\u044f\",\"\\u0433\\u0443\\u0431\\u0435\\u0440\\u043d\\u0430\\u0442\\u043e\\u0440\",\"\\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u0443\",\"\\u043e\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u043e\\u0432\\u0430\\u043d\",\"\\u043d\\u043e\\u0432\\u0443\\u044e\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u0432\\u043e\\u0434\\u0441\\u0442\\u0432\\u0430\",\"\\u043a\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440\\u044b\",\"\\u0443\\u0440\\u043e\\u0432\\u0435\\u043d\\u044c\",\"\\u0442\\u0435\",\"\\u0440\\u0430\\u0434\\u044b\",\"\\u043b\\u0435\\u043d\\u0442\\u0430\",\"\\u043a\\u043e\\u043b\\u043b\\u0435\\u043a\\u0446\\u0438\\u044e\",\"\\u0430\\u043c\\u0435\\u0440\\u0438\\u043a\\u0430\\u043d\\u0441\\u043a\\u0430\\u044f\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u0442\\u043e\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b\\u0430\",\"\\u0432\\u043e\\u043e\\u0440\\u0443\\u0436\\u0435\\u043d\\u043d\\u044b\\u0445\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0445\",\"\\u043f\\u0440\\u043e\\u0432\\u0435\\u043b\",\"\\u043b\\u0438\\u0431\\u043e\",\"\\u043f\\u0435\\u0440\\u0435\\u0433\\u043e\\u0432\\u043e\\u0440\\u044b\",\"\\u043f\\u043b\\u0430\\u043d\\u0438\\u0440\\u0443\\u0435\\u0442\",\"\\u0441\\u0438\\u043b\\u044b\",\"\\u043e\\u0431\\u044a\\u044f\\u0441\\u043d\\u0438\\u043b\",\"\\u043a\\u0440\\u0435\\u043c\\u043b\\u044f\",\"\\u0438\\u0433\\u043e\\u0440\\u044c\",\"\\u043b\\u0438\\u0433\\u0438\",\"\\u0446\\u0435\\u043d\\u0442\\u0440\",\"\\u043c\\u0443\\u0436\\u0447\\u0438\\u043d\\u0443\",\"\\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u044e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u043a\\u0443\",\"\\u0438\\u0442\\u043e\\u0433\\u0435\",\"\\u0434\\u043e\\u043c\\u043e\\u0432\",\"\\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u044c\",\"\\u0446\\u0435\\u043d\\u044b\",\"\\u044e\\u0436\\u043d\\u043e\\u0439\",\"\\u043f\\u043e\\u0440\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u0430\\u0446\\u0438\\u0439\",\"\\u043f\\u0440\\u0435\\u0434\\u043b\\u043e\\u0436\\u0438\\u043b\\u0438\",\"\\u0437\\u0434\\u0435\\u0441\\u044c\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u043e\\u0439\",\"\\u043c\\u0435\\u0442\\u0440\\u043e\",\"\\u0434\\u0442\\u043f\",\"\\u043a\\u0440\\u044b\\u043c\\u0443\",\"\\u043a\\u0443\\u043b\\u044c\\u0442\\u0443\\u0440\\u044b\",\"300\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0443\",\"\\u0442\\u0435\\u0440\\u0440\\u0438\\u0442\\u043e\\u0440\\u0438\\u044e\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0443\",\"\\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u044f\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u044c\",\"\\u043f\\u043e\\u044f\\u0432\\u0438\\u043b\\u0430\\u0441\\u044c\",\"\\u0443\\u0433\\u043e\\u043b\\u043e\\u0432\\u043d\\u043e\\u0433\\u043e\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u044b\",\"\\u0441\\u0430\\u043d\\u043a\\u0442-\\u043f\\u0435\\u0442\\u0435\\u0440\\u0431\\u0443\\u0440\\u0433\\u0435\",\"\\u043a\\u043e\\u043d\\u0444\\u043b\\u0438\\u043a\\u0442\",\"\\u043d\\u0438\\u043a\\u043e\\u0433\\u0434\\u0430\",\"\\u0432\\u044b\\u0448\\u0435\\u043b\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\\u0430\",\"\\u043f\\u0440\\u043e\\u0438\\u0437\\u043e\\u0448\\u0435\\u0434\\u0448\\u0435\\u0433\\u043e\",\"\\u0440\\u044f\\u0434\\u043e\\u043c\",\"\\u0434\\u0438\\u0440\\u0435\\u043a\\u0442\\u043e\\u0440\\u0430\",\"\\u043e\\u0431\\u0449\\u0435\\u0439\",\"\\u0443\\u043d\\u0438\\u0432\\u0435\\u0440\\u0441\\u0438\\u0442\\u0435\\u0442\\u0430\",\"\\u0431\\u0440\\u0435\\u043d\\u0434\",\"\\u0432\\u0442\\u043e\\u0440\\u043e\\u043c\",\"\\u0438\\u0441\\u0442\\u043e\\u0447\\u043d\\u0438\\u043a\\u0438\",\"\\u0444\\u043e\\u0442\\u043e\\u0433\\u0440\\u0430\\u0444\\u0438\\u0438\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\\u043d\\u0435\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u0438\\u0440\\u043e\\u0432\\u043a\\u0438\",\"\\u043c\\u043e\\u043a\",\"\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0435\\u0440\\u0441\\u0442\\u0432\\u0430\",\"\\u0430\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430\",\"\\u043c\\u043e\\u0433\\u043b\\u0438\",\"\\u043b\\u0435\\u0442\\u043e\\u043c\",\"\\u0441\\u043e\\u044e\\u0437\\u0430\",\"\\u043f\\u0440\\u0438\\u043d\\u044f\\u0442\\u044c\",\"\\u043f\\u0435\\u0440\\u0432\\u0443\\u044e\",\"\\u043e\\u0440\\u0443\\u0436\\u0438\\u0435\",\"\\u043c\\u043e\\u0441\\u043a\\u043e\\u0432\\u0441\\u043a\\u043e\\u0433\\u043e\",\"mail\",\"\\u0441\\u0430\\u0430\\u043a\\u0430\\u0448\\u0432\\u0438\\u043b\\u0438\",\"\\u0440\\u0443\\u0431\\u043b\\u044f\",\"\\u0430\\u0432\\u0442\\u043e\\u043c\\u043e\\u0431\\u0438\\u043b\\u0435\\u0439\",\"\\u043f\\u043e\\u0433\\u0438\\u0431\",\"\\u0438\\u0441\\u0441\\u043b\\u0435\\u0434\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f\",\"\\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0438\",\"\\u0432\\u0430\\u0448\\u0438\\u043d\\u0433\\u0442\\u043e\\u043d\",\"\\u043f\\u0435\\u0440\\u0432\\u044b\\u0435\",\"\\u0437\\u0430\\u043f\\u0440\\u0435\\u0449\\u0435\\u043d\\u0430\",\"\\u043f\\u043e\\u0431\\u0435\\u0434\\u044b\",\"\\u043e\\u0431\\u0432\\u0438\\u043d\\u0438\\u043b\\u0438\",\"\\u0432\\u0441\\u0435\\u0439\",\"\\u043f\\u043e\\u043b\\u0438\\u0446\\u0438\\u044e\",\"\\u0441\\u0442\\u0430\\u043d\\u0446\\u0438\\u0438\",\"\\u0441\\u0434\\u0435\\u043b\\u0430\\u043b\",\"\\u0438\\u0441\\u043b\\u0430\\u043c\\u0441\\u043a\\u043e\\u0435\",\"\\u043f\\u0440\\u043e\\u0445\\u043e\\u0434\\u0438\\u0442\",\"\\u043f\\u043e\\u0434\\u043f\\u0438\\u0441\\u0430\\u043b\",\"\\u0447\\u043b\\u0435\\u043d\\u043e\\u0432\",\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u043b\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0439\",\"\\u043e\\u0431\\u044a\\u0435\\u043a\\u0442\\u043e\\u0432\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u043e\",\"\\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u0445\",\"\\u0438\\u043d\\u0446\\u0438\\u0434\\u0435\\u043d\\u0442\\u0430\",\"\\u0432\\u043e\\u043a\\u0440\\u0443\\u0433\",\"\\u0433\\u043b\\u0430\\u0432\\u043d\\u043e\\u0433\\u043e\",\"\\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\",\"\\u043e\\u0442\\u043d\\u043e\\u0448\\u0435\\u043d\\u0438\\u0439\",\"\\u043f\\u0440\\u043e\\u0448\\u043b\\u043e\\u043c\",\"\\u0443\\u043f\\u0440\\u0430\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0440\\u0433\\u0430\\u043d\\u0438\\u0437\\u0430\\u0446\\u0438\\u044f\",\"\\u0441\\u0435\\u0440\\u0438\\u0438\",\"\\u0440\\u0430\\u0439\\u043e\\u043d\\u0430\",\"\\u043b\\u0438\\u0446\\u0430\",\"\\u0440\\u044b\\u043d\\u043a\\u0430\",\"of\",\"\\u0432\\u043a\\u043e\\u043d\\u0442\\u0430\\u043a\\u0442\\u0435\",\"\\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u044f\",\"\\u0431\\u0435\\u043b\\u043e\\u0433\\u043e\",\"\\u0443\\u0434\\u0430\\u0440\",\"\\u043f\\u043e\\u0434\\u043c\\u043e\\u0441\\u043a\\u043e\\u0432\\u044c\\u0435\",\"\\u0432\\u043e\\u043f\\u0440\\u043e\\u0441\\u044b\",\"\\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0435\\u043d\\u0438\\u0435\",\"\\u0441\\u0430\\u043c\\u043e\\u0439\",\"\\u0432\\u0441\\u0435\\u0433\\u0434\\u0430\",\"\\u0440\\u043e\\u043b\\u044c\",\"\\u0441\\u0442\\u0440\\u043e\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u0430\",\"\\u043d\\u0438\\u043a\\u0430\\u043a\\u0438\\u0445\",\"\\u0441\\u0435\\u0440\\u0435\\u0434\\u0438\\u043d\\u0435\",\"\\u0442\\u0435\\u043b\\u043e\",\"\\u0448\\u0435\\u0441\\u0442\\u0438\",\"\\u0441\\u0435\\u043c\\u044c\\u0438\",\"\\u043f\\u043e\\u044f\\u0432\\u0438\\u043b\\u043e\\u0441\\u044c\",\"\\u0434\\u043e\\u043a\\u0443\\u043c\\u0435\\u043d\\u0442\\u044b\",\"\\u0432\\u0435\\u0441\\u0442\\u0438\",\"\\u0443\\u0431\\u0438\\u0439\\u0441\\u0442\\u0432\\u043e\",\"\\u0430\\u0432\\u0438\\u0430\\u043a\\u043e\\u043c\\u043f\\u0430\\u043d\\u0438\\u0438\",\"\\u0441\\u043e\\u0431\\u0435\\u0441\\u0435\\u0434\\u043d\\u0438\\u043a\",\"\\u043c\\u0430\\u0442\\u0447\\u0430\",\"\\u043c\\u0435\\u043d\\u044c\\u0448\\u0435\",\"\\u0432\\u043c\\u0435\\u0441\\u0442\\u043e\",\"\\u0432\\u0435\\u0434\\u043e\\u043c\\u0441\\u0442\\u0432\\u0435\",\"\\u0440\\u0435\\u0448\\u0438\\u043b\\u0438\",\"\\u0440\\u0430\\u043d\\u0435\\u043d\\u0438\\u044f\",\"\\u0445\\u043e\\u0442\\u044f\",\"\\u0446\\u0435\\u043d\\u0430\",\"\\u043c\\u0447\\u0441\",\"\\u0440\\u0443\\u043a\\u043e\\u0432\\u043e\\u0434\\u0441\\u0442\\u0432\\u043e\",\"\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0439\",\"\\u0440\\u043e\\u0441\\u0442\\u0430\",\"\\u043a\\u0438\\u043c\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0435\\u0442\",\"\\u043c\\u0430\\u0442\\u0447\",\"\\u043f\\u043e\\u0441\\u0442\\u0440\\u0430\\u0434\\u0430\\u0432\\u0448\\u0438\\u0445\",\"\\u043f\\u0440\\u0435\\u043c\\u044c\\u0435\\u0440-\\u043c\\u0438\\u043d\\u0438\\u0441\\u0442\\u0440\",\"\\u043d\\u0430\\u0448\\u0435\\u0439\",\"\\u0441\\u043b\\u0435\\u0434\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0438\",\"\\u043f\\u0440\\u0430\\u0432\",\"new\",\"\\u0441\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u0438\\u0435\",\"\\u0434\\u0432\\u0443\\u043c\\u044f\",\"\\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u044c\",\"\\u043f\\u0440\\u043e\\u0448\\u043b\\u0430\",\"\\u043d\\u0430\\u0440\\u0443\\u0448\\u0435\\u043d\\u0438\\u0435\",\"\\u0443\\u0442\\u0432\\u0435\\u0440\\u0436\\u0434\\u0430\\u0435\\u0442\",\"\\u0434\\u043e\\u043d\\u0431\\u0430\\u0441\\u0441\\u0430\",\"\\u0443\\u0447\\u0430\\u0441\\u0442\\u043d\\u0438\\u043a\\u0438\",\"\\u0441\\u043e\\u0433\\u043b\\u0430\\u0448\\u0435\\u043d\\u0438\\u044f\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]}},\"selected\":{\"id\":\"1046\"},\"selection_policy\":{\"id\":\"1047\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1025\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\"},\"ticker\":{\"id\":\"1016\"}},\"id\":\"1015\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1011\"},\"ticker\":null},\"id\":\"1014\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1001\"}},\"id\":\"1037\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1016\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1038\",\"type\":\"HoverTool\"},{\"attributes\":{\"axis\":{\"id\":\"1015\"},\"dimension\":1,\"ticker\":null},\"id\":\"1018\",\"type\":\"Grid\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1041\",\"type\":\"Title\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
              "  var render_items = [{\"docid\":\"690dfd8c-9797-4160-9739-5794400bc121\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"ed149242-ee80-4db0-b370-6046bf61aed8\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNicpGCnpcZd",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1: Рубрикация: самописный word2vec\n",
        "\n",
        "Проверьте, как модель выше работает в задаче рубрикации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjXmjT6co412",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_labels = set(train_dataset[\"topic\"].dropna().tolist())\n",
        "target_labels -= {'Бизнес', 'Крым', 'Культпросвет'}\n",
        "target_labels = list(target_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhtCTnwHo45V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafe1012-9c08-420e-e5ff-ff5cfcf5127f"
      },
      "source": [
        "pattern = r'(\\b{}\\b)'.format('|'.join(target_labels))\n",
        "\n",
        "train_with_topics = train_dataset[train_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
        "train_with_topics = train_with_topics\n",
        "test_with_topics = test_dataset[test_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  return func(self, *args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-krzBVroJcFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from razdel import tokenize\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def get_text_embedding(model, embeddings, vocabulary, phrase):\n",
        "    embeddings = np.array([embeddings[vocabulary.get_index(word.text.lower())]\n",
        "                           if word.text.lower() in vocabulary.vocab\n",
        "                           else np.zeros((model.embeddings.embedding_dim,))\n",
        "                           for word in tokenize(phrase)])\n",
        "    return np.mean(embeddings, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgy4Jsvg5XJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_train = np.zeros((train_with_topics.shape[0], model.embeddings.embedding_dim))\n",
        "for i, embedding in enumerate(train_with_topics[\"text\"]):\n",
        "    X_train[i, :] = get_text_embedding(model, embeddings, vocabulary, embedding)\n",
        "\n",
        "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_test = np.zeros((test_with_topics.shape[0], model.embeddings.embedding_dim))\n",
        "for i, embedding in enumerate(test_with_topics[\"text\"]):\n",
        "    X_test[i, :] = get_text_embedding(model, embeddings, vocabulary, embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78vVwxxFdzEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6802c456-b84f-4e8b-bdf0-20b21bf9c6b2"
      },
      "source": [
        "%%time\n",
        "\n",
        "cls = LogisticRegression(multi_class='ovr', penalty='l2', class_weight='balanced', verbose=1)\n",
        "cls.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.4 s, sys: 5.84 s, total: 17.3 s\n",
            "Wall time: 8.82 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    8.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKAYCzlQeS60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "13436932-1ea3-4c61-c0a3-e1090a987c38"
      },
      "source": [
        "y_pred = cls.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.67      0.54      1663\n",
            "           1       0.57      0.60      0.58      2447\n",
            "           2       0.64      0.43      0.51      4324\n",
            "           3       0.63      0.65      0.64      1182\n",
            "           4       0.35      0.45      0.39       847\n",
            "           5       0.17      0.67      0.27       258\n",
            "           6       0.74      0.71      0.73      3185\n",
            "           7       0.72      0.68      0.70      1995\n",
            "           8       0.77      0.64      0.70      4291\n",
            "           9       0.69      0.62      0.65      2156\n",
            "          11       0.79      0.74      0.76      2119\n",
            "          12       0.91      0.91      0.91      3429\n",
            "          13       0.54      0.82      0.65      2191\n",
            "          14       0.83      0.62      0.71      1177\n",
            "\n",
            "    accuracy                           0.66     31264\n",
            "   macro avg       0.63      0.66      0.62     31264\n",
            "weighted avg       0.69      0.66      0.67     31264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pEZRooLlsIYT",
        "colab": {}
      },
      "source": [
        "from razdel import tokenize\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def get_text_embedding(model, embeddings, vocabulary, phrase):\n",
        "    embeddings = np.array([embeddings[vocabulary.get_index(word.text.lower())]\n",
        "                           if word.text.lower() in vocabulary.vocab\n",
        "                           else np.zeros((model.embeddings.embedding_dim,))\n",
        "                           for word in tokenize(phrase)])\n",
        "    return np.mean(embeddings, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pzkaJ6R4sIYX",
        "colab": {}
      },
      "source": [
        "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_train = np.zeros((train_with_topics.shape[0], model.embeddings.embedding_dim))\n",
        "for i, embedding in enumerate(train_with_topics[\"text\"]):\n",
        "    X_train[i, :] = get_text_embedding(model, embeddings, vocabulary, embedding)\n",
        "\n",
        "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_test = np.zeros((test_with_topics.shape[0], model.embeddings.embedding_dim))\n",
        "for i, embedding in enumerate(test_with_topics[\"text\"]):\n",
        "    X_test[i, :] = get_text_embedding(model, embeddings, vocabulary, embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XcNVpvKmsIYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6802c456-b84f-4e8b-bdf0-20b21bf9c6b2"
      },
      "source": [
        "%%time\n",
        "\n",
        "cls = LogisticRegression(multi_class='ovr', penalty='l2', class_weight='balanced', verbose=1)\n",
        "cls.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.4 s, sys: 5.84 s, total: 17.3 s\n",
            "Wall time: 8.82 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    8.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GTCbYilcsIYf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "13436932-1ea3-4c61-c0a3-e1090a987c38"
      },
      "source": [
        "y_pred = cls.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.67      0.54      1663\n",
            "           1       0.57      0.60      0.58      2447\n",
            "           2       0.64      0.43      0.51      4324\n",
            "           3       0.63      0.65      0.64      1182\n",
            "           4       0.35      0.45      0.39       847\n",
            "           5       0.17      0.67      0.27       258\n",
            "           6       0.74      0.71      0.73      3185\n",
            "           7       0.72      0.68      0.70      1995\n",
            "           8       0.77      0.64      0.70      4291\n",
            "           9       0.69      0.62      0.65      2156\n",
            "          11       0.79      0.74      0.76      2119\n",
            "          12       0.91      0.91      0.91      3429\n",
            "          13       0.54      0.82      0.65      2191\n",
            "          14       0.83      0.62      0.71      1177\n",
            "\n",
            "    accuracy                           0.66     31264\n",
            "   macro avg       0.63      0.66      0.62     31264\n",
            "weighted avg       0.69      0.66      0.67     31264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEnfVqVYpxgR",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2: Самописный CBoW\n",
        "\n",
        "Сделайте аналогичную модель, но в архитектуре CBoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnWadOJoo6Ye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9f33562c-24ff-4a4e-d4c5-381cdd1d48b0"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "import time\n",
        "\n",
        "class CBoWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        projections = self.embeddings.forward(inputs)\n",
        "        output = self.out_layer.forward(projections)\n",
        "        return output\n",
        "      \n",
        "\n",
        "cbow = CBoWModel(vocabulary.size, 32)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "cbow = cbow.to(device)\n",
        "\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "optimizer = optim.Adam(cbow.parameters(), lr=0.01)\n",
        "loss_function = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "for step, (batch_contexts, batch_centrals) in enumerate(get_next_batch(contexts, window_size=2, batch_size=512, epochs_count=5)):\n",
        "    logits = cbow(batch_contexts) # Прямой проход\n",
        "    loss = loss_function(logits, batch_centrals) # Подсчёт ошибки\n",
        "    loss.backward() # Подсчёт градиентов dL/dw\n",
        "    optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
        "    optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step = 348000, Avg Loss = 7.9585, Time = 10.48s\n",
            "Step = 349000, Avg Loss = 7.9414, Time = 10.48s\n",
            "Step = 350000, Avg Loss = 7.9569, Time = 10.48s\n",
            "Step = 351000, Avg Loss = 7.9220, Time = 10.48s\n",
            "Step = 352000, Avg Loss = 7.9376, Time = 10.49s\n",
            "Step = 353000, Avg Loss = 7.9542, Time = 10.49s\n",
            "Step = 354000, Avg Loss = 7.9314, Time = 10.49s\n",
            "Step = 355000, Avg Loss = 7.9428, Time = 10.49s\n",
            "Step = 356000, Avg Loss = 7.9330, Time = 10.48s\n",
            "Step = 357000, Avg Loss = 7.9404, Time = 10.48s\n",
            "Step = 358000, Avg Loss = 7.9651, Time = 10.49s\n",
            "Step = 359000, Avg Loss = 7.9418, Time = 10.49s\n",
            "Step = 360000, Avg Loss = 7.9287, Time = 10.48s\n",
            "Step = 361000, Avg Loss = 7.9502, Time = 10.49s\n",
            "Step = 362000, Avg Loss = 7.9466, Time = 10.49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zMiY_pko2cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embs = cbow.embeddings.weight.cpu().data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcQT7oQCYaQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('embs2.npy', 'ab') as f:\n",
        "  np.save(f, embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBqSNPjJq6FU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "11761294-32f8-467d-af7e-73a5b3635cf6"
      },
      "source": [
        "most_similar(embs, vocabulary, 'путин')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['путин',\n",
              " 'мединский',\n",
              " 'гройсман',\n",
              " 'президент',\n",
              " 'колокольцев',\n",
              " 'сафронков',\n",
              " 'жириновский',\n",
              " 'лавров',\n",
              " 'брынзак',\n",
              " 'бухаров']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtVIUBHp6Qu",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3*: Negative Sampling\n",
        "\n",
        "Реализуйте negative sampling вместо полного softmax'а"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsHuaHR0frYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5caa5bd9-ecf4-434d-ad61-bbad0036f728"
      },
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "def build_contexts(tokenized_texts, vocabulary, window_size):\n",
        "\n",
        "    contexts = []\n",
        "    for tokens in tokenized_texts:\n",
        "        for i in range(len(tokens)):\n",
        "            central_word = vocabulary.get_index(tokens[i])\n",
        "            context = [vocabulary.get_index(tokens[i + delta]) for delta in range(-window_size, window_size + 1) \n",
        "                       if delta != 0 and i + delta >= 0 and i + delta < len(tokens)]\n",
        "            if len(context) != 2 * window_size:\n",
        "                continue\n",
        "\n",
        "            neg_samples = np.random.randint(0, vocabulary.size-1, size=window_size*2).tolist()\n",
        "\n",
        "            contexts.append((central_word, context, [neg_samples]))\n",
        "            \n",
        "    return contexts\n",
        "\n",
        "contexts = build_contexts(texts, vocabulary, window_size=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 44s, sys: 5.55 s, total: 3min 50s\n",
            "Wall time: 3min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM52hnIcVuvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d784ff9-aac2-4bac-ce41-071522b128b4"
      },
      "source": [
        "print(contexts[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1568, [17232, 26343, 135, 371], [[71024, 24798, 102218, 83042]]), (135, [26343, 1568, 371, 2], [[54581, 37165, 93694, 33600]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnIv-66wMfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(context, window_size, batch_size, epochs_count):\n",
        "    assert batch_size % (window_size * 2) == 0\n",
        "    central_words, pos, neg = zip(*context)\n",
        "    batch_size //= (window_size * 2)\n",
        "    \n",
        "    for epoch in range(epochs_count):\n",
        "        indices = np.arange(len(pos))\n",
        "        np.random.shuffle(indices)\n",
        "        batch_begin = 0\n",
        "        while batch_begin < len(pos):\n",
        "            batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
        "            batch_centrals, batch_pos, batch_neg = [], [], []\n",
        "            for data_ind in batch_indices:\n",
        "                central_word, pos_words, neg_words = central_words[data_ind], pos[data_ind], neg[data_ind]\n",
        "                batch_pos.extend(pos_words)\n",
        "                batch_centrals.extend([central_word] * len(pos_words))\n",
        "                batch_neg.extend(neg_words * len(pos_words))\n",
        "                \n",
        "            batch_begin += batch_size\n",
        "            yield torch.cuda.LongTensor(batch_centrals), torch.cuda.LongTensor(batch_pos), torch.cuda.LongTensor(batch_neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEampLfh7D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, embedding_size, vocab_size):\n",
        "        super(SkipGramNeg, self).__init__()\n",
        "        self.embeddings_target = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.embeddings_context = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "    def forward(self, target_word, context_word, negative_example):\n",
        "        emb_target = self.embeddings_target(target_word)\n",
        "        emb_context = self.embeddings_context(context_word)\n",
        "        score = torch.mul(emb_target, emb_context).squeeze()\n",
        "        score = torch.sum(score, dim=1)\n",
        "        out = F.logsigmoid(score)\n",
        "        \n",
        "        emb_negative = self.embeddings_context(negative_example)\n",
        "        neg_score = torch.bmm(emb_negative, emb_target.unsqueeze(2)).squeeze(2)\n",
        "        neg_score = torch.sum(neg_score, dim=1)\n",
        "        neg_out = F.logsigmoid(-1 * neg_score)\n",
        "        return -1 * torch.mean(out + neg_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NKymYR1QCSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SkipGramNeg(32, vocabulary.size)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = model.to(device)\n",
        "\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, (batch_centrals, batch_pos, batch_neg) in enumerate(get_batch(contexts, window_size=2, batch_size=512, epochs_count=10)):\n",
        "\n",
        "    loss = model(batch_centrals, batch_pos, batch_neg) \n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss += loss\n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tPPAt83tW1_D",
        "colab": {}
      },
      "source": [
        "embs = model.embeddings_context.weight.cpu().data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69ePwJR2W1_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c37fbb6a-a6e2-4dd3-9141-333464751b61"
      },
      "source": [
        "most_similar(embs, vocabulary, 'путин')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['путин',\n",
              " 'правительство',\n",
              " 'неоднократно',\n",
              " 'также',\n",
              " 'активисты',\n",
              " 'считает',\n",
              " 'сергей',\n",
              " 'его',\n",
              " 'сроки',\n",
              " 'был']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-XMEfZ4XVoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from razdel import tokenize\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def get_text_embedding(model, embeddings, vocabulary, phrase):\n",
        "    embeddings = np.array([embeddings[vocabulary.get_index(word.text.lower())]\n",
        "                           if word.text.lower() in vocabulary.vocab\n",
        "                           else np.zeros((model.embeddings_context.embedding_dim,))\n",
        "                           for word in tokenize(phrase)])\n",
        "    return np.mean(embeddings, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "roEbDNsqW8dT",
        "colab": {}
      },
      "source": [
        "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_train = np.zeros((train_with_topics.shape[0], model.embeddings_context.embedding_dim))\n",
        "for i, embedding in enumerate(train_with_topics[\"text\"]):\n",
        "    X_train[i, :] = get_text_embedding(model, embs, vocabulary, embedding)\n",
        "\n",
        "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_test = np.zeros((test_with_topics.shape[0], model.embeddings_context.embedding_dim))\n",
        "for i, embedding in enumerate(test_with_topics[\"text\"]):\n",
        "    X_test[i, :] = get_text_embedding(model, embs, vocabulary, embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fn-clHjKW8dY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "272d4c6a-5aa4-4180-fe8e-e4e8f84e521e"
      },
      "source": [
        "%%time\n",
        "\n",
        "cls = LogisticRegression(multi_class='ovr', penalty='l2', class_weight='balanced', verbose=1)\n",
        "cls.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17 s, sys: 9.6 s, total: 26.6 s\n",
            "Wall time: 13.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   13.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ldxzTJcAW8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f8f2af41-5665-4013-efa4-19914c66acdf"
      },
      "source": [
        "y_pred = cls.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.64      0.65      2119\n",
            "           1       0.87      0.84      0.85      3429\n",
            "           2       0.39      0.46      0.42      2447\n",
            "           3       0.61      0.47      0.53      4291\n",
            "           4       0.50      0.49      0.50      2156\n",
            "           5       0.40      0.55      0.46      1663\n",
            "           6       0.17      0.26      0.21       847\n",
            "           7       0.85      0.58      0.69      1177\n",
            "           9       0.44      0.23      0.30      4324\n",
            "          10       0.49      0.75      0.60      2191\n",
            "          11       0.65      0.53      0.58      1995\n",
            "          12       0.52      0.49      0.51      1182\n",
            "          13       0.14      0.53      0.22       258\n",
            "          14       0.01      0.50      0.01         8\n",
            "          15       0.64      0.63      0.64      3185\n",
            "\n",
            "    accuracy                           0.53     31272\n",
            "   macro avg       0.49      0.53      0.48     31272\n",
            "weighted avg       0.57      0.53      0.54     31272\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35hwVrw4sxgs",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised targets\n",
        "У пословных моделей есть ряд проблем. Основная - в разных контекстах у одинаковых токенов будут одинаковые представления. Кроме того, наивные Skip-gram и CBoW не учитывают порядок токенов в контексте. \n",
        "\n",
        "Как извлечь информацию из сырых текстов? Чему должны учиться модели, из которых мы получим наши представления?\n",
        "\n",
        "1.   **Skip-gram**\n",
        "2.   **CBoW**\n",
        "3.   LM: language modeling (ELMo, ULMFiT)\n",
        "4.   NSP: next sentence prediction (BERT, в модификациях иногда убирается)\n",
        "5.   MLM: masked language modeling (BERT, основной таргет)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnfBooJYq-Nv",
        "colab_type": "text"
      },
      "source": [
        "# Языковые модели\n",
        "\n",
        "\n",
        "\n",
        "Языковое моделирование - довольно древняя и понятная задача. Статистичская языковая модель (statistical language model) - вероятностное распределение над последовательностями слов $$P(w_1,...,w_n)$$\n",
        "\n",
        "Другая постановка:\n",
        "$$P(w_n | w_1,...,w_{n-1}) = P(w_n|w_1^{n-1})$$\n",
        "\n",
        "N-граммные модели:\n",
        "\n",
        "$$P(w_n|w_1^{n-1}) \\approx P(w_n|w_{n-N+1}^{n-1})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsKkyKOZv0s7",
        "colab_type": "text"
      },
      "source": [
        "## Пример N-граммной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1C3q4SrWLjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NGramModel:\n",
        "    def __init__(self, vocabulary, n=4):\n",
        "        self.n = n\n",
        "        self.n_grams = [Counter() for _ in range(n+1)]\n",
        "        self.vocabulary = vocabulary\n",
        "    \n",
        "    def collect_n_grams(self, tokens):\n",
        "        indices = [vocabulary.get_index(token) for token in tokens]\n",
        "        count = len(indices)\n",
        "        for n in range(self.n + 1):\n",
        "            for i in range(min(count - n + 1, count)):\n",
        "                n_gram = indices[i:i+n]\n",
        "                self.n_grams[n][tuple(n_gram)] += 1\n",
        "                \n",
        "    def normalize(self):\n",
        "        for n in range(self.n, 0, -1):\n",
        "            current_n_grams = self.n_grams[n]\n",
        "            for words, count in current_n_grams.items():\n",
        "                prev_order_n_gram_count = self.n_grams[n-1][words[:-1]]\n",
        "                current_n_grams[words] = count / prev_order_n_gram_count\n",
        "        self.n_grams[0][tuple()] = 1.0\n",
        "    \n",
        "    def predict(self, context):\n",
        "        indices = [vocabulary.get_index(token) for token in context]\n",
        "        context = tuple(indices[-self.n + 1:])\n",
        "        step_probabilities = np.zeros((self.vocabulary.size, ), dtype=np.float64)\n",
        "        for shift in range(self.n):\n",
        "            current_n = self.n - shift\n",
        "            wanted_context_length = current_n - 1\n",
        "            if wanted_context_length > len(context):\n",
        "                continue\n",
        "            start_index = len(context) - wanted_context_length\n",
        "            wanted_context = context[start_index:]\n",
        "            \n",
        "            s = 0.0\n",
        "            for index in range(self.vocabulary.size):\n",
        "                n_gram = wanted_context + (index,)\n",
        "                p = self.n_grams[current_n].get(n_gram, 0)\n",
        "                step_probabilities[index] = p\n",
        "                s += p\n",
        "            if s != 0.0:\n",
        "                break\n",
        "        return step_probabilities\n",
        "\n",
        "vocabulary.word2index[\"<eos>\"] = vocabulary.size\n",
        "vocabulary.index2word.append(\"<eos>\")\n",
        "n_gram_model = NGramModel(vocabulary)\n",
        "for text in texts[:1000]:\n",
        "    n_gram_model.collect_n_grams(text + [\"<eos>\"])\n",
        "n_gram_model.normalize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTXLmc1dbOaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "893e566d-aa1b-4596-c801-01ce9914ba42"
      },
      "source": [
        "seed = [\"путин\"]\n",
        "while seed[-1] != \"<eos>\":\n",
        "    proba = n_gram_model.predict(seed)\n",
        "    seed.append(np.random.choice(vocabulary.index2word, size=1, p=proba)[0])\n",
        "    print(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['путин', 'не']\n",
            "['путин', 'не', 'вышел']\n",
            "['путин', 'не', 'вышел', 'к']\n",
            "['путин', 'не', 'вышел', 'к', 'митингующим']\n",
            "['путин', 'не', 'вышел', 'к', 'митингующим', 'после']\n",
            "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара']\n",
            "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара', 'в']\n",
            "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара', 'в', 'кемерове']\n",
            "['путин', 'не', 'вышел', 'к', 'митингующим', 'после', 'пожара', 'в', 'кемерове', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvVIpD7mv6Nv",
        "colab_type": "text"
      },
      "source": [
        "## ELMo (Embeddings from Language Models)\n",
        "\n",
        "Оригинальная статья: https://arxiv.org/pdf/1802.05365.pdf\n",
        "\n",
        "The Illustrated BERT, ELMo and co.: http://jalammar.github.io/illustrated-bert/\n",
        "\n",
        "Как применить?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73HlNt0Lfu12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "edd52709-298e-4117-daed-d0abee1f8a02"
      },
      "source": [
        "!wget http://vectors.nlpl.eu/repository/11/195.zip\n",
        "!mkdir elmo && mv 195.zip elmo/195.zip && cd elmo && unzip 195.zip && rm 195.zip && cd ..\n",
        "!ls elmo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-12 14:27:43--  http://vectors.nlpl.eu/repository/11/195.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206977021 (197M) [application/zip]\n",
            "Saving to: ‘195.zip’\n",
            "\n",
            "195.zip             100%[===================>] 197.39M  8.60MB/s    in 30s     \n",
            "\n",
            "2020-08-12 14:28:15 (6.55 MB/s) - ‘195.zip’ saved [206977021/206977021]\n",
            "\n",
            "Archive:  195.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.hdf5              \n",
            "  inflating: options.json            \n",
            "  inflating: README                  \n",
            "  inflating: vocab.txt               \n",
            "meta.json  model.hdf5  options.json  README  vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VnzcdhvkflG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "def create_embeddings(text, alone_sequence = False):\n",
        "  elmo = Elmo(options_file=\"elmo/options.json\", weight_file=\"elmo/model.hdf5\", num_output_representations=2).cuda()\n",
        "  if alone_sequence == True:\n",
        "    character_ids = batch_to_ids([text]).cuda()\n",
        "  else:\n",
        "    character_ids = batch_to_ids(text).cuda()\n",
        "  embeddings = elmo(character_ids)['elmo_representations'][0].detach().cpu().numpy()\n",
        "  del character_ids\n",
        "  del elmo\n",
        "  gc.collect()\n",
        "  return np.mean(embeddings, axis=1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6TrSZEvkfjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_batches = [texts[i:i+40] for i in range(0,len(texts[:80]), 40)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1HJocbkfc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "embeddings = [create_embeddings(batch) for batch in data_batches]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ-qbn5Bw4mj",
        "colab_type": "text"
      },
      "source": [
        "### Задание 4: Рубрикация: ELMo\n",
        "\n",
        "Проверьте, как ELMo работает в задаче рубрикации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wg3n2KzFsNHY",
        "colab": {}
      },
      "source": [
        "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_train = np.zeros((train_with_topics.shape[0], embeddings[0].shape[1]))\n",
        "for i, embedding in enumerate(train_with_topics[\"text\"]):\n",
        "    X_train[i, :] = create_embeddings(embedding, alone_sequence = True)\n",
        "\n",
        "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_test = np.zeros((test_with_topics.shape[0], embeddings[0].shape[1]))\n",
        "for i, embedding in enumerate(test_with_topics[\"text\"]):\n",
        "    X_test[i, :] = create_embeddings(embedding, alone_sequence = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZSqPjeOnsNHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6802c456-b84f-4e8b-bdf0-20b21bf9c6b2"
      },
      "source": [
        "%%time\n",
        "\n",
        "cls = LogisticRegression(multi_class='ovr', penalty='l2', class_weight='balanced', verbose=1)\n",
        "cls.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.4 s, sys: 5.84 s, total: 17.3 s\n",
            "Wall time: 8.82 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    8.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I_sprcynsNHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "13436932-1ea3-4c61-c0a3-e1090a987c38"
      },
      "source": [
        "y_pred = cls.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.67      0.54      1663\n",
            "           1       0.57      0.60      0.58      2447\n",
            "           2       0.64      0.43      0.51      4324\n",
            "           3       0.63      0.65      0.64      1182\n",
            "           4       0.35      0.45      0.39       847\n",
            "           5       0.17      0.67      0.27       258\n",
            "           6       0.74      0.71      0.73      3185\n",
            "           7       0.72      0.68      0.70      1995\n",
            "           8       0.77      0.64      0.70      4291\n",
            "           9       0.69      0.62      0.65      2156\n",
            "          11       0.79      0.74      0.76      2119\n",
            "          12       0.91      0.91      0.91      3429\n",
            "          13       0.54      0.82      0.65      2191\n",
            "          14       0.83      0.62      0.71      1177\n",
            "\n",
            "    accuracy                           0.66     31264\n",
            "   macro avg       0.63      0.66      0.62     31264\n",
            "weighted avg       0.69      0.66      0.67     31264\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8T2fh_Nwhyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}